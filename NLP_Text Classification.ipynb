{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from math import sqrt\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "import scipy.signal\n",
    "from scipy.signal import fftconvolve, convolve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ipywidgets import interact\n",
    "import random as ran\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from dateutil.relativedelta import *\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, RidgeCV, LassoCV, ElasticNetCV, LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, KFold, GridSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn import datasets\n",
    "from textblob import TextBlob, Word\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from textacy.preprocess import preprocess_text\n",
    "\n",
    "from gensim import corpora, models, matutils\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as sm\n",
    "from statsmodels.tsa.stattools import acf, pacf, adfuller\n",
    "from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import patsy\n",
    "from itertools import combinations\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import graphviz\n",
    "import json\n",
    "import requests\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from time import sleep\n",
    "import re\n",
    "import twitter\n",
    "\n",
    "%matplotlib inline\n",
    "#plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and document a working model, prototype, recommendation, or solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP Text Classification using Twitter API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goals\n",
    "\n",
    "Classify whether a tweet comes from Donald Trump or Nancy Pelosi -> Can we correctly identify which of these two politicians tweeted what?\n",
    "\n",
    "Steps:\n",
    "- Create a developer account on Twitter\n",
    "- Create a method to pull a list of tweets from the Twitter API\n",
    "- Perform proper preprocessing on our text\n",
    "- Engineer sentiment feature in our dataset using TextBlob\n",
    "- Explore supervised classification techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter API Developer Registration\n",
    "\n",
    "- Register for a Twitter account -> requirement in order to have a \"developer\" account.\n",
    "\n",
    "  [Twitter Rest API](https://dev.twitter.com/rest/public)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an \"App\"\n",
    "\n",
    "- Register an \"app\" on Twitter ([apps.twitter.com](https://apps.twitter.com/)).\n",
    "\n",
    "- **Note**: A placeholder can be used for the required website field (e.g., https://www.placeholder.com).\n",
    "\n",
    "- Reference the corresponding keys and tokens that Twitter generates after setting up the app.\n",
    "\n",
    "- These keys/tokens will be used with the app to communicate with the Twitter API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Python Twitter API Library\n",
    "\n",
    "Python Twitter Library provided by [Python Twitter Tools](http://mike.verdone.ca/twitter/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#$ pip install python-twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### App Keys and Tokens\n",
    "\n",
    "Take note of the app consumer API keys and access tokens that will be used to connect to Twitter and mine tweets from the official Twitter accounts of Donald Trump and Nancy Pelosi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter API Key Setup\n",
    "\n",
    "Fill in the information below with the keys from account.\n",
    "\n",
    "- **consumer_key** - Found in the app page under the \"Keys and tokens\": (API key)\n",
    "- **consumer_secret** - Under **consumer_key** in the \"Keys and tokens\" tab: (API secret key)\n",
    "- **access_token_key** - Click the button to generate access token: (Access token)\n",
    "- **access_token_secret** - Under **access_token_key**: (Access token secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import twitter, datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: EXCLUDING KEYS AND SECRETS FOR SECURITY PURPOSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_keys = {'consumer_key':        '',\n",
    "                'consumer_secret':     '',\n",
    "                'access_token_key':    '',\n",
    "                'access_token_secret': ''}\n",
    "\n",
    "api = twitter.Api(consumer_key         =   twitter_keys['consumer_key'],\n",
    "                  consumer_secret      =   twitter_keys['consumer_secret'],\n",
    "                  access_token_key     =   twitter_keys['access_token_key'],\n",
    "                  access_token_secret  =   twitter_keys['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `TweetMiner` class structure\n",
    "\n",
    "The following code will provide connectivity to Twitter. The class has the ability to make requests and can eventually transform the JSON responses into DataFrames.\n",
    "\n",
    "**Note:** \"result_limit\" is used to limit the number of tweets that are pulled per instance request.  Setting it to a lower value until the bugs are worked out of the request, and captured the data wanted, is essential to avoiding the rate limit blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetMiner(object):\n",
    "\n",
    "    result_limit    =   20    \n",
    "    api             =   False\n",
    "    data            =   []\n",
    "    \n",
    "    twitter_keys = {'consumer_key':        '',\n",
    "                    'consumer_secret':     '',\n",
    "                    'access_token_key':    '',\n",
    "                    'access_token_secret': ''}\n",
    "    \n",
    "    def __init__(self, keys_dict, api, result_limit=20):\n",
    "        \n",
    "        self.api = api\n",
    "        self.twitter_keys = keys_dict\n",
    "        self.result_limit = result_limit\n",
    "        \n",
    "    def mine_user_tweets(self, user='TWeichle', mine_retweets=False, max_pages=5):\n",
    "\n",
    "        data           =  []\n",
    "        last_tweet_id  =  False\n",
    "        page           =  1\n",
    "        \n",
    "        while page <= max_pages:\n",
    "            \n",
    "            if last_tweet_id:\n",
    "                statuses = self.api.GetUserTimeline(screen_name=user, count=self.result_limit, max_id=last_tweet_id-1)        \n",
    "            else:\n",
    "                statuses = self.api.GetUserTimeline(screen_name=user, count=self.result_limit)\n",
    "                \n",
    "            for item in statuses:\n",
    "\n",
    "                mined = {'tweet_id':        item.id,\n",
    "                         'handle':          item.user.name,\n",
    "                         'retweet_count':   item.retweet_count,\n",
    "                         'text':            item.text,\n",
    "                         'mined_at':        datetime.now(),\n",
    "                         'created_at':      item.created_at}\n",
    "                \n",
    "                last_tweet_id = item.id\n",
    "                data.append(mined)\n",
    "                \n",
    "            page += 1\n",
    "            \n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Data\n",
    "\"Mine\" data from the Twitter API.\n",
    "\n",
    "1. Mine Trump tweets\n",
    "- Create a Trump tweet DataFrame\n",
    "- Mine Pelosi tweets\n",
    "- Create a Pelosi tweet DataFrame\n",
    "- Append Trump and Pelosi tweet DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a TweetMiner class\n",
    "# -> Pass the 'twitter_keys' dictionary and api as arguments\n",
    "#miner = TweetMiner(twitter_keys, api, result_limit=2)\n",
    "miner = TweetMiner(twitter_keys, api, result_limit=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the TweetMiner's `mine_user_tweets()` method, providing twitter handles to pull the tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mine Trump tweets\n",
    "#trump_tweets = miner.mine_user_tweets(user='realDonaldTrump', max_pages=5)\n",
    "trump_tweets = miner.mine_user_tweets(user='realDonaldTrump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count number of items in list\n",
    "len(trump_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tweet_id': 1105904905888415744,\n",
       " 'handle': 'Donald J. Trump',\n",
       " 'retweet_count': 6760,\n",
       " 'text': 'https://t.co/2qWkPuFDL6',\n",
       " 'mined_at': datetime.datetime(2019, 3, 13, 14, 16, 12, 87965),\n",
       " 'created_at': 'Wed Mar 13 18:54:10 +0000 2019'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display first item in list\n",
    "trump_tweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tweet DataFrame\n",
    "trump_df = pd.DataFrame(trump_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 1000, Cols: 6\n"
     ]
    }
   ],
   "source": [
    "# Return the number of rows and columns (dimensionality) of the DataFrame\n",
    "print('Rows: {}, Cols: {}'.format(trump_df.shape[0], trump_df.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mine Pelosi tweets\n",
    "#pelosi_tweets = miner.mine_user_tweets(user='SpeakerPelosi', max_pages=5)\n",
    "pelosi_tweets = miner.mine_user_tweets('SpeakerPelosi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count number of items in list\n",
    "len(pelosi_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tweet_id': 1105929991852826627,\n",
       " 'handle': 'Nancy Pelosi',\n",
       " 'retweet_count': 178,\n",
       " 'text': 'Looking forward to my conversation with President @KerstiKaljulaid of Estonia today. Tune in as I welcome her to th… https://t.co/VO7qbHgq4T',\n",
       " 'mined_at': datetime.datetime(2019, 3, 13, 14, 16, 22, 440601),\n",
       " 'created_at': 'Wed Mar 13 20:33:51 +0000 2019'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display first item in list\n",
    "pelosi_tweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tweet DataFrame\n",
    "pelosi_df = pd.DataFrame(pelosi_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 1000, Cols: 6\n"
     ]
    }
   ],
   "source": [
    "# Return the number of rows and columns (dimensionality) of the DataFrame\n",
    "print('Rows: {}, Cols: {}'.format(pelosi_df.shape[0], pelosi_df.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate DataFrames\n",
    "# Note: axis=0 for rows, axis=1 for columns\n",
    "#       ignore_index=False\n",
    "tweets = pd.concat([trump_df, pelosi_df], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 2000, Cols: 6\n"
     ]
    }
   ],
   "source": [
    "# Return the number of rows and columns (dimensionality) of the DataFrame\n",
    "print('Rows: {}, Cols: {}'.format(tweets.shape[0], tweets.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 6 columns):\n",
      "created_at       2000 non-null object\n",
      "handle           2000 non-null object\n",
      "mined_at         2000 non-null datetime64[ns]\n",
      "retweet_count    2000 non-null int64\n",
      "text             2000 non-null object\n",
      "tweet_id         2000 non-null int64\n",
      "dtypes: datetime64[ns](1), int64(2), object(3)\n",
      "memory usage: 93.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Print a concise summary of a DataFrame including the index dtype and column dtypes, non-null values, and memory usage\n",
    "# Note: Useful to quickly see if null values exist \n",
    "tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>handle</th>\n",
       "      <th>mined_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wed Mar 13 18:54:10 +0000 2019</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2019-03-13 14:16:12.087965</td>\n",
       "      <td>6760</td>\n",
       "      <td>https://t.co/2qWkPuFDL6</td>\n",
       "      <td>1105904905888415744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wed Mar 13 16:48:29 +0000 2019</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2019-03-13 14:16:12.087972</td>\n",
       "      <td>17361</td>\n",
       "      <td>Republican Senators are overthinking tomorrow’...</td>\n",
       "      <td>1105873274804813824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wed Mar 13 16:43:14 +0000 2019</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2019-03-13 14:16:12.087973</td>\n",
       "      <td>10777</td>\n",
       "      <td>Democrats will have a unanimous vote on a 20% ...</td>\n",
       "      <td>1105871954001739782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wed Mar 13 14:28:54 +0000 2019</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2019-03-13 14:16:12.087974</td>\n",
       "      <td>4372</td>\n",
       "      <td>RT @GeraldoRivera: @SpeakerPelosi statements v...</td>\n",
       "      <td>1105838146057588737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wed Mar 13 14:28:50 +0000 2019</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2019-03-13 14:16:12.087975</td>\n",
       "      <td>6436</td>\n",
       "      <td>RT @GeraldoRivera: As #RobertMueller approache...</td>\n",
       "      <td>1105838130685493248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>Thu Jun 07 14:58:53 +0000 2018</td>\n",
       "      <td>Nancy Pelosi</td>\n",
       "      <td>2019-03-13 14:16:23.725136</td>\n",
       "      <td>91</td>\n",
       "      <td>I’m speaking live with reporters at the Capito...</td>\n",
       "      <td>1004739477640802309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>Thu Jun 07 14:18:20 +0000 2018</td>\n",
       "      <td>Nancy Pelosi</td>\n",
       "      <td>2019-03-13 14:16:23.725137</td>\n",
       "      <td>44</td>\n",
       "      <td>Tune in as I speak with reporters live at the ...</td>\n",
       "      <td>1004729273620619264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>Thu Jun 07 13:08:47 +0000 2018</td>\n",
       "      <td>Nancy Pelosi</td>\n",
       "      <td>2019-03-13 14:16:23.725139</td>\n",
       "      <td>603</td>\n",
       "      <td>RT @NydiaVelazquez: Last week, we learned that...</td>\n",
       "      <td>1004711771121311744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>Thu Jun 07 01:34:34 +0000 2018</td>\n",
       "      <td>Nancy Pelosi</td>\n",
       "      <td>2019-03-13 14:16:23.725140</td>\n",
       "      <td>1709</td>\n",
       "      <td>“The building of a nation united not on every ...</td>\n",
       "      <td>1004537064493387777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>Wed Jun 06 17:27:13 +0000 2018</td>\n",
       "      <td>Nancy Pelosi</td>\n",
       "      <td>2019-03-13 14:16:23.725141</td>\n",
       "      <td>218</td>\n",
       "      <td>RT @RulesDemocrats: If you're frustrated by in...</td>\n",
       "      <td>1004414420494245888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          created_at           handle  \\\n",
       "0     Wed Mar 13 18:54:10 +0000 2019  Donald J. Trump   \n",
       "1     Wed Mar 13 16:48:29 +0000 2019  Donald J. Trump   \n",
       "2     Wed Mar 13 16:43:14 +0000 2019  Donald J. Trump   \n",
       "3     Wed Mar 13 14:28:54 +0000 2019  Donald J. Trump   \n",
       "4     Wed Mar 13 14:28:50 +0000 2019  Donald J. Trump   \n",
       "1995  Thu Jun 07 14:58:53 +0000 2018     Nancy Pelosi   \n",
       "1996  Thu Jun 07 14:18:20 +0000 2018     Nancy Pelosi   \n",
       "1997  Thu Jun 07 13:08:47 +0000 2018     Nancy Pelosi   \n",
       "1998  Thu Jun 07 01:34:34 +0000 2018     Nancy Pelosi   \n",
       "1999  Wed Jun 06 17:27:13 +0000 2018     Nancy Pelosi   \n",
       "\n",
       "                       mined_at  retweet_count  \\\n",
       "0    2019-03-13 14:16:12.087965           6760   \n",
       "1    2019-03-13 14:16:12.087972          17361   \n",
       "2    2019-03-13 14:16:12.087973          10777   \n",
       "3    2019-03-13 14:16:12.087974           4372   \n",
       "4    2019-03-13 14:16:12.087975           6436   \n",
       "1995 2019-03-13 14:16:23.725136             91   \n",
       "1996 2019-03-13 14:16:23.725137             44   \n",
       "1997 2019-03-13 14:16:23.725139            603   \n",
       "1998 2019-03-13 14:16:23.725140           1709   \n",
       "1999 2019-03-13 14:16:23.725141            218   \n",
       "\n",
       "                                                   text             tweet_id  \n",
       "0                               https://t.co/2qWkPuFDL6  1105904905888415744  \n",
       "1     Republican Senators are overthinking tomorrow’...  1105873274804813824  \n",
       "2     Democrats will have a unanimous vote on a 20% ...  1105871954001739782  \n",
       "3     RT @GeraldoRivera: @SpeakerPelosi statements v...  1105838146057588737  \n",
       "4     RT @GeraldoRivera: As #RobertMueller approache...  1105838130685493248  \n",
       "1995  I’m speaking live with reporters at the Capito...  1004739477640802309  \n",
       "1996  Tune in as I speak with reporters live at the ...  1004729273620619264  \n",
       "1997  RT @NydiaVelazquez: Last week, we learned that...  1004711771121311744  \n",
       "1998  “The building of a nation united not on every ...  1004537064493387777  \n",
       "1999  RT @RulesDemocrats: If you're frustrated by in...  1004414420494245888  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the first 5 rows and the last 5 rows of the DataFrame\n",
    "tweets.head().append(tweets.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TextBlob: Simplified Text Processing\n",
    "[TextBlob](https://textblob.readthedocs.io/en/dev/) is a Python library for processing textual data. It provides a simple API for diving into common natural language processing (NLP) tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Republican Senators are overthinking tomorrow’s vote on National Emergency. It is very simply Border Security/No Cr… https://t.co/RuQzOUPmi3\n"
     ]
    }
   ],
   "source": [
    "# Print the second tweet\n",
    "print(tweets.text[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A general text block, meant for larger bodies of text (especially those containing sentences)\n",
    "tweet_1 = TextBlob(tweets.text.values[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Republican', 'Senators', 'are', 'overthinking', 'tomorrow', '’', 's', 'vote', 'on', 'National', 'Emergency', 'It', 'is', 'very', 'simply', 'Border', 'Security/No', 'Cr…', 'https', 't.co/RuQzOUPmi3'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A list-like collection of words\n",
    "tweet_1.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"Republican Senators are overthinking tomorrow’s vote on National Emergency.\"),\n",
       " Sentence(\"It is very simply Border Security/No Cr… https://t.co/RuQzOUPmi3\")]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A list-like collection of sentences\n",
    "tweet_1.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"republican senators are overthinking tomorrow’s vote on national emergency. it is very simply border security/no cr… https://t.co/ruqzoupmi3\")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns new object with all lower-cased characters\n",
    "tweet_1.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "created_at       0\n",
       "handle           0\n",
       "mined_at         0\n",
       "retweet_count    0\n",
       "text             0\n",
       "tweet_id         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the missing values in each column of a DataFrame - sum() works because True is 1 and False is 0\n",
    "tweets.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a vertical bar plot by number of missing values per column using matplotlib\n",
    "# Note: figsize: a tuple (width, height) in inches\n",
    "tweets.isnull().sum().plot.bar(figsize=(10, 8));\n",
    "plt.title('Number of null values per column');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2.000000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13211.375500</td>\n",
       "      <td>1.071445e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13305.429539</td>\n",
       "      <td>3.033260e+16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.004414e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1050.750000</td>\n",
       "      <td>1.052834e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9807.000000</td>\n",
       "      <td>1.082052e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22747.250000</td>\n",
       "      <td>1.094719e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>86197.000000</td>\n",
       "      <td>1.105930e+18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       retweet_count      tweet_id\n",
       "count    2000.000000  2.000000e+03\n",
       "mean    13211.375500  1.071445e+18\n",
       "std     13305.429539  3.033260e+16\n",
       "min        17.000000  1.004414e+18\n",
       "25%      1050.750000  1.052834e+18\n",
       "50%      9807.000000  1.082052e+18\n",
       "75%     22747.250000  1.094719e+18\n",
       "max     86197.000000  1.105930e+18"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe numeric columns\n",
    "# Generates descriptive summary statistics of the central tendency, dispersion, and shape of the distribution\n",
    "# Note: By default only numeric (int64) fields are returned\n",
    "#       Excludes \"NaN\" (missing) values\n",
    "# Remove multiple columns\n",
    "# Note: axis=0 for rows, 1 for columns\n",
    "tweets.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>handle</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1939</td>\n",
       "      <td>2</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Sat Dec 22 14:44:28 +0000 2018</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>MAKE AMERICA GREAT AGAIN!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            created_at           handle  \\\n",
       "count                             2000             2000   \n",
       "unique                            1939                2   \n",
       "top     Sat Dec 22 14:44:28 +0000 2018  Donald J. Trump   \n",
       "freq                                 4             1000   \n",
       "\n",
       "                             text  \n",
       "count                        2000  \n",
       "unique                       1996  \n",
       "top     MAKE AMERICA GREAT AGAIN!  \n",
       "freq                            3  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe object columns (e.g. categorical, strings, or timestamps)\n",
    "# Generates descriptive summary statistics of the count, unique values, top values, and frequency\n",
    "# Note: \"top\" is the most common value; \"freq\" is the most common value's frequency\n",
    "#       Excludes \"NaN\" (missing) values\n",
    "# Remove multiple columns\n",
    "# Note: axis=0 for rows, 1 for columns\n",
    "tweets.describe(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Donald J. Trump    1000\n",
       "Nancy Pelosi       1000\n",
       "Name: handle, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Categorical column frequency\n",
    "# Returns counts of unique values in descending order (first element is the most frequently-occurring element)\n",
    "# Note: Excludes NA values by default\n",
    "tweets.handle.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create indicator for whether a tweet was from Donald Trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lambda function: apply an arbitrary function to each value of a Pandas column, storing the result in a new column\n",
    "tweets['trump_handle'] = tweets.handle.apply(lambda handle: 1 if handle == 'Donald J. Trump' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Any interesting n-grams for Donald Trump?\n",
    "\n",
    "- Set up a vectorizer from sklearn\n",
    "- Fit the text of Trump's tweets with an n-gram range from 2 to 4\n",
    "- Determine the most common n-grams\n",
    "\n",
    "**Note:** How does keeping or removing stopwords affect the results?\n",
    "\n",
    "Keeping stopwords will result in many more common n-grams containing stop words -> REMOVE STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate TfidfVectorizer to convert a collection of raw documents to a matrix of TF-IDF features\n",
    "# -> Equivalent to CountVectorizer followed by TfidfTransformer\n",
    "# Note: stop_words: if a string, it is passed to _check_stop_list and the appropriate stop list is returned;\n",
    "#                   'english' is currently the only supported string value\n",
    "#       ngram_range: tuple (min_n, max_n); the lower and upper boundary of the range of n-values for \n",
    "#                    different n-grams to be extracted; all values of n such that min_n <= n <= max_n will be used\n",
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('border security', 42),\n",
       " ('fake news', 29),\n",
       " ('southern border', 26),\n",
       " ('united states', 24),\n",
       " ('president trump', 21),\n",
       " ('white house', 17),\n",
       " ('michael cohen', 13),\n",
       " ('kim jong', 12),\n",
       " ('north korea', 12),\n",
       " ('donald trump', 11),\n",
       " ('border https', 11),\n",
       " ('rt realdonaldtrump', 11),\n",
       " ('rt gopchairwoman', 10),\n",
       " ('james comey', 10),\n",
       " ('nancy pelosi', 9),\n",
       " ('rt whitehouse', 9),\n",
       " ('security wall', 9),\n",
       " ('rt paulsperry_', 9),\n",
       " ('great people', 9),\n",
       " ('approval rating', 9)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pulls all of Trump's tweet texts into one giant string\n",
    "summaries = \"\".join(trump_df.text)\n",
    "\n",
    "# Return a callable that handles preprocessing and tokenization\n",
    "ngrams_summaries = vect.build_analyzer()(summaries)\n",
    "\n",
    "# Dict subclass for counting hashable items; sometimes called a bag or multiset\n",
    "# -> Elements are stored as dictionary keys and their counts are stored as dictionary values\n",
    "# 20 most common elements\n",
    "Counter(ngrams_summaries).most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Any interesting n-grams for Nancy Pelosi?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate TfidfVectorizer to convert a collection of raw documents to a matrix of TF-IDF features\n",
    "# -> Equivalent to CountVectorizer followed by TfidfTransformer\n",
    "# Note: stop_words: if a string, it is passed to _check_stop_list and the appropriate stop list is returned;\n",
    "#                   'english' is currently the only supported string value\n",
    "#       ngram_range: tuple (min_n, max_n); the lower and upper boundary of the range of n-values for \n",
    "#                    different n-grams to be extracted; all values of n such that min_n <= n <= max_n will be used\n",
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pre existing', 35),\n",
       " ('health care', 26),\n",
       " ('trump admin', 21),\n",
       " ('live capitol', 20),\n",
       " ('existing conditions', 20),\n",
       " ('pre existing conditions', 20),\n",
       " ('speaking reporters', 19),\n",
       " ('trump administration', 18),\n",
       " ('reporters live', 17),\n",
       " ('supreme court', 17),\n",
       " ('reporters live capitol', 17),\n",
       " ('american people', 16),\n",
       " ('tune https', 15),\n",
       " ('working families', 15),\n",
       " ('amp https', 14),\n",
       " ('americans pre', 14),\n",
       " ('americans pre existing', 13),\n",
       " ('forthepeople act', 12),\n",
       " ('pm et', 11),\n",
       " ('press conference', 11)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pulls all of Trump's tweet texts into one giant string\n",
    "summaries = \"\".join(pelosi_df.text)\n",
    "\n",
    "# Return a callable that handles preprocessing and tokenization\n",
    "ngrams_summaries = vect.build_analyzer()(summaries)\n",
    "\n",
    "# Dict subclass for counting hashable items; sometimes called a bag or multiset\n",
    "# -> Elements are stored as dictionary keys and their counts are stored as dictionary values\n",
    "# 20 most common elements\n",
    "Counter(ngrams_summaries).most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sentiment Analysis\n",
    "\n",
    "Understanding how positive or negative a document (piece of text) is. There are many ways in practice to compute a sentiment value. For example:\n",
    "- Have a list of \"positive\" words and a list of \"negative\" words and count how many occur in a document. \n",
    "- Train a classifier given many examples of \"positive\" documents and \"negative\" documents. \n",
    "    - Note that this technique is often just an automated way to derive the first (e.g., using bag-of-words with logistic regression, a coefficient is assigned to each word!).\n",
    "\n",
    "For the most accurate sentiment analysis, train a custom sentiment model based on documents that are particular to the application. Generic models often do not work as well as hoped.\n",
    "\n",
    "Always make sure to double-check that the algorithm is working by manually verifying that scores correctly correspond to positive/negative reviews! Otherwise, you may be using numbers that are not accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract sentiment from a tweet parsed with TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Republican Senators are overthinking tomorrow’s vote on National Emergency. It is very simply Border Security/No Cr… https://t.co/RuQzOUPmi3\n"
     ]
    }
   ],
   "source": [
    "print(tweet_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Polarity: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Polarity ranges from -1 (most negative) to 1 (most positive)\n",
    "print('Sentiment Polarity:', round(tweet_1.sentiment.polarity, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the sentiment for every tweet in the full tweets dataset as a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that accepts text and returns the polarity\n",
    "# -> Polarity ranges from -1 (most negative) to 1 (most positive)\n",
    "def detect_sentiment(text):\n",
    "    return TextBlob(text).sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>handle</th>\n",
       "      <th>mined_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>trump_handle</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wed Mar 13 18:54:10 +0000 2019</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2019-03-13 14:16:12.087965</td>\n",
       "      <td>6760</td>\n",
       "      <td>https://t.co/2qWkPuFDL6</td>\n",
       "      <td>1105904905888415744</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wed Mar 13 16:48:29 +0000 2019</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2019-03-13 14:16:12.087972</td>\n",
       "      <td>17361</td>\n",
       "      <td>Republican Senators are overthinking tomorrow’...</td>\n",
       "      <td>1105873274804813824</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wed Mar 13 16:43:14 +0000 2019</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2019-03-13 14:16:12.087973</td>\n",
       "      <td>10777</td>\n",
       "      <td>Democrats will have a unanimous vote on a 20% ...</td>\n",
       "      <td>1105871954001739782</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wed Mar 13 14:28:54 +0000 2019</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2019-03-13 14:16:12.087974</td>\n",
       "      <td>4372</td>\n",
       "      <td>RT @GeraldoRivera: @SpeakerPelosi statements v...</td>\n",
       "      <td>1105838146057588737</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wed Mar 13 14:28:50 +0000 2019</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2019-03-13 14:16:12.087975</td>\n",
       "      <td>6436</td>\n",
       "      <td>RT @GeraldoRivera: As #RobertMueller approache...</td>\n",
       "      <td>1105838130685493248</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at           handle                   mined_at  \\\n",
       "0  Wed Mar 13 18:54:10 +0000 2019  Donald J. Trump 2019-03-13 14:16:12.087965   \n",
       "1  Wed Mar 13 16:48:29 +0000 2019  Donald J. Trump 2019-03-13 14:16:12.087972   \n",
       "2  Wed Mar 13 16:43:14 +0000 2019  Donald J. Trump 2019-03-13 14:16:12.087973   \n",
       "3  Wed Mar 13 14:28:54 +0000 2019  Donald J. Trump 2019-03-13 14:16:12.087974   \n",
       "4  Wed Mar 13 14:28:50 +0000 2019  Donald J. Trump 2019-03-13 14:16:12.087975   \n",
       "\n",
       "   retweet_count                                               text  \\\n",
       "0           6760                            https://t.co/2qWkPuFDL6   \n",
       "1          17361  Republican Senators are overthinking tomorrow’...   \n",
       "2          10777  Democrats will have a unanimous vote on a 20% ...   \n",
       "3           4372  RT @GeraldoRivera: @SpeakerPelosi statements v...   \n",
       "4           6436  RT @GeraldoRivera: As #RobertMueller approache...   \n",
       "\n",
       "              tweet_id  trump_handle  sentiment  \n",
       "0  1105904905888415744             1     0.0000  \n",
       "1  1105873274804813824             1     0.0000  \n",
       "2  1105871954001739782             1     0.0000  \n",
       "3  1105838146057588737             1     0.5000  \n",
       "4  1105838130685493248             1    -0.0625  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new DataFrame column for sentiment (Warning: SLOW!)\n",
    "tweets['sentiment'] = tweets.text.apply(detect_sentiment)\n",
    "tweets.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Box plot of sentiment grouped by handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAncAAAGTCAYAAABK9zRrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3X98lfV9///Hk0QUxQqoZcoPtZNtweh0TeumzBIoUHUDttna6Dpro660pPvYdVaafvrr28yfndsHBaaNVTs9Wl0VrDqkIWmHrF2x/uBH1kqVAmJbFa2CAUzy+v5xrmQnMQlgzsmR6zzvt9u55Vzv631d1+scw+Uz7+uXIgIzMzMzS4dhxS7AzMzMzPLH4c7MzMwsRRzuzMzMzFLE4c7MzMwsRRzuzMzMzFLE4c7MzMwsRRzuzKzgJN0m6evFrqPYBvoeJH1c0qo8badF0iX5WNf+bCufn8HM3j6HO7MSImmTpDZJOyS9IukhSROKXVcuSSHpxGLXYWZ2oHK4Mys9fx4RI4FjgF8DC4tcT8Eoy/s5Mysp3umZlaiI2AXcB0zuapN0hKQ7JL0o6ZeSvtgVjiQtlnRfTt9rJDUlAWqqpK2SviDppWSE8ML+ti3pUkkbJW2XtEzSsUn7D5MuTyWji+f3sWyZpG8k23lO0vxktK88md8iqUHSY8AbwHskHZtsZ3uy3Utz1tfjUGnXZ8mZ3iRpgaQNyWjntyQdkjP/zyQ9KelVSaslnZIz7zRJP5X0uqR7gO7l+v9qtFDSbyX9j6TpSeOHJT3eq+PfS3pggHUdJ+mxZNuPSjoqZ9l7Jf0q2c4PJZ3U6/u4KRnVfV3SjyX9bs78GUltv5V0I6ABPswfSFqRfO8/k/SRvXx+M8sDhzuzEiXpUOB84Ec5zQuBI4D3AB8A/ga4OJn398ApyXlVfwrUAhfF/z7D8HeAo4BxwEXAzZJ+v4/tTgOuAj5CdvTwl8DdABFxVtLtDyNiZETc00fplwJnA6cCfwTM7aPPx4DLgMOT9WeArcCxwHnAP3YFp310ITAL+F3g94AvJp/lj4Bbgb8FjgT+FVgm6WBJw4EHgG8DY4B7gb/ay3ZOB54l+z1+GfiupDHAMuAESRU5ff86WXd/LiD73+7dwHDgcznzHgEmJfN+CtzZa9ka4KvAaGAj0JB83qOAf08+/1HAL4Az+9q4pMOAFcBdyXZqgEW5QdLMCsPhzqz0PCDpVeA1YAZwHWRHxMiGvQUR8XpEbAK+QTYoERFvkA0U/wT8G1AXEVt7rfv/RsTuiPgB8BDZANfbhcCtEfHTiNgNLAD+RNLx+1j/R4B/iYitEfEKcHUffW6LiPUR0U42dE4BPh8RuyLiSeCbXZ9rH90YEVsiYjvZoFOTtF8K/GtE/DgiOiLidmA38MfJ6yDgnyPizYi4D/jJXrbzm5z+9wA/A85Nvqd7yH7/JAHpeOB7A6zrWxHx84hoA75DNgwDEBG3Jv+NdwNfAf5Q0hE5y343Iv47+f7uzFn2HGBDRNwXEW8C/wz8qp/t/xmwKSK+FRHtEfFTssHwvL18B2Y2SA53ZqVnbkSMAg4G5gM/kNQ16jac7EhXl1+SHYkDICL+m+zIksgGhlyvRMTOXsse28f2j83dRkTsAF7O3c5eHAtsyZne0kef3LZjge0R8Xqv2vZ1e73Xl/u5jgP+Pjkk+2oSmick848Fns8Z2exadiB99e/a1u3ABZJENph+Jwln/ckNXW8AI6H7sPbVkn4h6TVgU9LnqL0tS6/vPqm1r+8fst/N6b2+mwvJhm0zKyCHO7MSlYw0fRfoIDuy9RLwJtn/KXeZCDzfNSHp02RD4Tbgil6rHJ0cistddlsfm96Wu41kmSNzt7MXLwDjc6b7uto3NyBtA8ZIOrxXbV3b2wkcmjOvr/CRu43cz7UFaIiIUTmvQyMik9Q5LgljucsOpK/+2wAi4kfAHuBPyR5yHeiQ7EAuAOYAHyR7CP74pL3fc+dyvEDOd5HU2t/V1luAH/T6bkZGxLy3WbeZ7SOHO7MSpaw5ZM+rao2IDrKjcQ2SDpd0HPBZsodgkfR7wNfJHhr8GHCFpFN7rfarkoYn5+T9GdnzzHq7C7hY0qmSDgb+EfhxchgYslfwvmeA0r8D/J2kcZJGAZ8f6HNGxBZgNXCVpEOSCx5q+d/zzJ4EzpE0JhnB/D99rObTksYn5799gewhUoBbgE9KOj35Pg+TdG4SJP8LaAc+I6lc0l8C7x+oVrLnpn1G0kGSPgxUAA/nzL8DuBFoj4i3ez+5w8keOn6ZbKj9x/1Y9iHgJEl/qewFLJ+h/5G47wG/J+ljyec5SNL7ep03aGYF4HBnVnoelLSD7Dl3DWQvilifzKsjO5L1LLCKbBC7Nfkf+b8B10TEUxHxDNmQ8+0koEH2UN4rZEea7gQ+GRH/03vjEdEE/F+y51+9QPYihY/mdPkKcHtyKK+vc/ZuAR4FngaeIBt+2smOQPanhuwI1TbgfuDLEbEimfdt4Cmyhycf5X+DW667knnPJq+vJ59lDdnz7m5MPvtG4OPJvD3AXybTr5A9n/G7A9QI8GOyFzq8RPa/zXkR8XLO/G8Dlbz9UTvIBsRfkh253EDPC2oGFBEvAR8me57jy0mtj/XT93VgJtn/ttvI/n5cQ3bk18wKSD1P7zAz23+SpgL/FhHj99a3ANs+G1gSEcfttfPbW/8m4JKI+H4h1r+ftYwge9HFHyUB28zsLTxyZ2YHFEkjJJ2THOocR/aWIfcXu64hMg/4iYOdmQ2kvNgFmJntJ5G9B9s9QBvZ88C+VNSKhkAygij6vq+fmVk3H5Y1MzMzSxEfljUzMzNLEYc7MzMzsxRxuDMzMzNLEYc7MzMzsxRxuDMzMzNLEYc7M7MBSHpE0kXFrsPMbF/5VihmZglJXwFOjIi/fgfUchuwNSK+WOxazOzA4pE7MzMzsxRxuDOzA5akz0t6XtLrkn4mabqkYZKulPQLSS9L+o6kMUn/4yWFpIskbZb0kqT6ZN6HgC8A50vaIemppL1F0iXJ+49LekzSDZJelfSspDOS9i2SfpN7CFfSwZKuT7b1a0lLkufDImmqpK2S/j5Z7gVJFyfzLgMuBK5IanlwKL9XMzuwOdyZ2QFJ0u8D84H3RcThwCxgE/AZso/o+gBwLPAKcFOvxacAvw9MB74kqSIi/gP4R+CeiBgZEX/Yz6ZPB54GjgTuAu4G3gecCPw1cKOkkUnfa4DfA05N5o+j56PSfgc4ImmvBW6SNDoibgbuBK5Navnz/fx6zKyEOdyZ2YGqAzgYmCzpoIjYFBG/AP4WqI+IrRGxG/gKcJ6k3GdpfzUi2iLiKeApoL8g15fnIuJbEdFB9vm2E4CvRcTuiHgU2AOcKEnApcDlEbE9Il4nGx4/mrOuN5Nl34yIh4EdZEOnmdnbVr73LmZm7zwRsVHS/yEb3k6StBz4LHAccL+kzpzuHcDYnOlf5bx/AxjJvvt1zvu2pJbebSOBo4FDgcezOQ8AAWU5fV+OiPZB1GJm9hYeuTOzA1ZE3BURU8gGuiB7GHQLcHZEjMp5HRIRz+/LKvNY3ktkg95JOXUcERH7Gt58KwMze1sc7szsgCTp9yVNk3QwsItskOoAlgANko5L+h0tac4+rvbXwPGSBr1vjIhO4BbgBknvTmoZJ2nWftTynsHWYWalx+HOzA5UBwNXkx0h+xXwbrJXu/4LsAx4VNLrwI/IXgSxL+5Nfr4s6ad5qPHzwEbgR5JeA77Pvp9T10j2fMJXJT2Qh1rMrET4JsZmZmZmKeKROzMzM7MUcbgzMzMzSxGHOzMzM7MUcbgzMzMzS5ED8ibGRx11VBx//PHFLsMOUDt37uSwww4rdhlmVoK8/7HBePzxx1+KiKP31u+ADHfHH388a9asKXYZdoBqaWlh6tSpxS7DzEqQ9z82GJJ+uS/9fFjWzMzMLEUc7szMzMxSxOHOzMzMLEUc7szMzMxSxOHOzMzMLEUc7szMzMxSxOHOzMzMLEUc7szMzMxSxOHOzMzMLEXyEu4k3SrpN5LW9TNfkv6fpI2Snpb0RznzLpL0TPK6KB/1mJmZmZWqfD1+7DbgRuCOfuafDUxKXqcDi4HTJY0BvgxUAQE8LmlZRLySp7rMukl6S1tEFKESMys1ZWVldHZ2dk8PGzaMjo6OIlZkaZaXkbuI+CGwfYAuc4A7IutHwChJxwCzgBURsT0JdCuAD+WjJrNcucHukksu6bPdzKwQuoLdyJEjWbx4MSNHjqSzs5OysrJil2YpNVTn3I0DtuRMb03a+ms3K4iI4MILL/SInZkNma5g9/rrr/MHf/AHvP76690Bz6wQ8nVYdm/6Gh6JAdrfugLpMuAygLFjx9LS0pK34qw0XHLJJbS0tLBjxw5aWlq45JJL+OY3v+nfJTMruOuuu67H/ue6665j3rx53v9YQShfIxiSjge+FxGVfcz7V6AlIjLJ9M+AqV2viPjbvvr1p6qqKtasWZOXuq00dB1+jQhaWlqYOnVqjzYzs0KR1D1y17X/Ofzww9mxY4f3P7ZfJD0eEVV76zdUh2WXAX+TXDX7x8BvI+IFYDkwU9JoSaOBmUmbWUFI4s477/S5dmY2ZIYNG8aOHTs4/PDD+Z//+Z/uYDdsmO9GZoWRl5E7SRmyo3BHAb8mewXsQQARsUTZ/5PeSPZiiTeAiyNiTbLsJ4AvJKtqiIhv7W17Hrmzt8NXy5pZsfhqWcuHfR25y8s5dxFRs5f5AXy6n3m3Arfmow6zgXQFua7DImZmQ6UryHn/Y0PBY8JmZmZmKeJwZ2ZmZpYiDndmZmZmKeJwZyUjk8lQWVnJ9OnTqaysJJMZ8I47ZmZmB6ShuomxWVFlMhnq6+tpbGyko6ODsrIyamtrAaipGfB6IDMzswOKw52VhIaGBi644ALq6upobW2loqKCCy64gIaGBoc7MzNLlbw9oWIo+T53tr+GDRvGyJEj2bVrF2+++SYHHXQQhxxyCDt27PDzHc2s4DKZDA0NDd1/XNbX1/sPS9tvQ3qfO7N3uq47xF9//fVMnjyZDRs28LnPfc53iDezgvNpITbUPHJnJUESY8aM4b777uveuZ533nls377dT6kws4KqrKxk7ty5PPDAA90jd13T69atK3Z5dgDxyJ1ZL5dcckmPc+4uueQSrr322mKXZWYpt2HDBt544423jNxt2rSp2KVZSvmYlJWE8vJybrrpJnbu3AnAzp07uemmmygv9983ZlZYw4cPZ/78+VRXV1NeXk51dTXz589n+PDhxS7NUsrhzkrCtGnT2LlzJ5s3b6azs5PNmzezc+dOpk2bVuzSzCzl9uzZw8KFC2lubqa9vZ3m5mYWLlzInj17il2apZSHLawkbNiwgREjRtDe3k5nZydlZWUcfPDBbNiwodilmVnKTZ48mblz5/Y4LeTCCy/kgQceKHZpllIeubOSsHXrVpYuXcqePXtobm5mz549LF26lK1btxa7NDNLufr6eu666y4WLlzI8uXLWbhwIXfddRf19fXFLs1SyuHOSsbKlSt7PH5s5cqVxS7JzEpATU0NI0eOZNq0acyYMYNp06YxcuRI3wbFCsbhzkrCmDFjuO666/jEJz7BQw89xCc+8Qmuu+46xowZU+zSzCzlZs2axdq1a5k3bx4PPvgg8+bNY+3atcyaNavYpVlK+Zw7KwmHHnoobW1tXHnlld1PqBg+fDiHHnposUszs5RbsWIF8+bNY9GiRbS0tLBo0SIAlixZUuTKLK08cmcl4fnnn+ewww5j3LhxDBs2jHHjxnHYYYfx/PPPF7s0M0u5iOCqq67q0XbVVVf5BupWMA53VhKGDx/OggULeO6552hqauK5555jwYIFvs+UmRWcJBYsWNCjbcGCBUgqUkWWdj4sayVhz5493HjjjZx22ml0dHTQ3NzMjTfe6PtMmVnBzZgxg8WLFwNwzjnn8KlPfYrFixczc+bMIldmaeVny1pJ8LMdzayYTjnlFNauXds9ffLJJ/P0008XsSI7EPnZsmY56uvrueCCC7qn169fz/r167nrrruKWJWZlYJMJtMj2AGsXbuWTCbj26FYQXjkzkrCQOe2HIj/BszswOH9j+XLvo7c+YIKKykRQXNzs3eoZjbkVq5cyYoVK3wDdSs4hzsrGXffffeA02ZmhVJbW0t1dTXl5eVUV1dTW1tb7JIsxXxY1kpC12GRiKClpYWpU6f2aDMzK5Sufc3KlSvp6OigrKyMadOmAd7/2P7xBRVmfZDEF7/4Raqrq4tdipmVmK5AZ1ZoPixrJSH3r+Ovf/3rfbabmRVCf1fl+2p9K5S8hDtJH5L0M0kbJV3Zx/wbJD2ZvH4u6dWceR0585blox6zvkyYMGHAaTOzQqipqWHmzJndh2clMXPmTN8GxQpm0OFOUhlwE3A2MBmokTQ5t09EXB4Rp0bEqcBC4Ls5s9u65kXE7MHWY9aXiRMnsmXLFs444wzuvfdezjjjDLZs2cLEiROLXZqZpVxdXR0rV67k+uuv55FHHuH6669n5cqV1NXVFbs0S6l8jNy9H9gYEc9GxB7gbmDOAP1rgEwetmu2z7qC3WOPPcZRRx3FY4891h3wzMwK6ZZbbuH888/n1ltv5dxzz+XWW2/l/PPP55Zbbil2aZZS+bigYhyQ+3/IrcDpfXWUdBxwApB7k59DJK0B2oGrI+KBfpa9DLgMYOzYsbS0tAy+cispl19+OS0tLezYsYOWlhYuv/xyVq9e7d8lMyuo3bt309TUxBVXXMEJJ5zAc889x7XXXsvu3bu9/7GCyEe46+vW2/2dpf5R4L6I6MhpmxgR2yS9B1gpaW1E/OItK4y4GbgZsrdCmTp16iDLtlJzww038Nhjj3XfCuXMM88EwL9LZlZIkviLv/iL7j8wL7/8cp555hmWLFni/Y8VRD4Oy24Fcs9MHw9s66fvR+l1SDYitiU/nwVagNPyUJNZDxMmTGD16tWceeaZvPTSS5x55pmsXr3aF1WY2ZBYsmQJxxxzDNOnT+eYY45hyZIlxS7JUiwfI3c/ASZJOgF4nmyAu6B3J0m/D4wG/iunbTTwRkTslnQUcCZwbR5qMuth8+bNHHnkkaxevZrVq1cDMGbMGDZv3lzkysws7caNG8f27dt5+eWX6ezs5OWXX2bEiBGMGTOm2KVZSg165C4i2oH5wHKgFfhORKyX9DVJuVe/1gB3R88bi1UAayQ9BTSTPeduw2BrMustk8lwxBFH9Hi24xFHHEEm42t7zKzwjjjiCJYvX86KFStYvnw5RxxxRLFLshTz48esJFRWVrJw4UKqq6u7z7lrbm6mrq6OdevWFbs8M0uxsrIyjj32WLZu3drdNn78eLZt20ZHR8cAS5r1tK+PH/MTKqwktLa2MmXKlB5tU6ZMobW1tUgVmVmpOOigg9i6dSuzZ8/m/vvvZ/bs2WzdupWDDjqo2KVZSnnkzlKh687vhXAg/hsxs3cOSYwYMYKHHnqIjo4OysrKOPfcc2lra/P+xfaLR+6spETEgK+77rqLE044gZUrVzLxcw+wcuVKTjjhBO666669LmtmNlg33HADdXV1zJo1i7q6Om644YZil2Qplo+rZc3e8bqe4VhXV8fmDa3UPVJBQ0ODn+1oZkPi4YcfZt26dd3n/M6ZM9CDnMwGx4dlreQcf+VDbLr63GKXYWYl4pRTTmHt2rWMHDmSnTt3cthhh7Fjxw5OPvlknn766WKXZwcQH5Y1MzN7B1iwYAFlZWXs2LGDiGDHjh2UlZWxYMGCYpdmKeVwZ2ZmVkBXXHEFRx99dI/7bB599NFcccUVxS7NUsrhzszMrIC2bt3KHXfcQXV1NeXl5VRXV3PHHXf0uO+dWT453JmZmZmliK+WNTMzK6Dx48fzkY98hFGjRrF582YmTpzIq6++yvjx44tdmqWUR+7MzMwKaO7cubz66qts2rSJzs5ONm3axKuvvsrcuXOLXZqllMOdmZlZAd1yyy371W42WA53ZmZmBbR7924A5s2bx4MPPsi8efN6tJvlm8+5MzMzGwKLFy9m8eLFxS7DSoBH7szMzIbAyJEjWbx4MSNHjix2KZZyDndmZmZDQBKf/vSnkVTsUizlfFjWzMxsCLz++us9fpoVikfuzMzMCqysrKx7xE4SZWVlRa7I0szhzszMrIDKy8vp6Ohg1KhR3HLLLYwaNYqOjg7Ky33wzArDv1lmZmYF9Oabb1JWVsYrr7zCpZdeCsCwYcN48803i1yZpZVH7szMzAook8lw3HHHsXLlSlasWMHKlSs57rjjyGQyxS7NUsojd2ZmZgXU0NDAkUceyfTp04kIJPHe976XhoYGampqil2epZDDnZmZWQGtX78eyD6h4pxzzuHhhx/2zYytoHxY1szMrMBmz57NokWLGDlyJIsWLWL27NnFLslSzCN3ZmZmBfbkk0/S3NxMR0cHzc3NPPnkk8UuyVLM4c7MzKyAJDFp0iTq6upobW2loqKCSZMmsWXLlmKXZinlw7JmZmYFNGPGDJqamjjrrLNYunQpZ511Fk1NTcyYMaPYpVlKeeTOzMysgJYvX86sWbNYsmQJixcvRhIzZ85k+fLlxS7NUiovI3eSPiTpZ5I2Srqyj/kfl/SipCeT1yU58y6S9Ezyuigf9ZiZmQ0VSXt9Pfroo0QEABHBo48+uk/Lmb0dgw53ksqAm4CzgclAjaTJfXS9JyJOTV7fTJYdA3wZOB14P/BlSaMHW5OZmdlQiYh9fh33+e/tV3+ztyMfI3fvBzZGxLMRsQe4G5izj8vOAlZExPaIeAVYAXwoDzWZmZmZlaR8nHM3Dsi95Gcr2ZG43v5K0lnAz4HLI2JLP8uO62sjki4DLgMYO3YsLS0tg6/cSpZ/f8ysWLz/sULLR7jr66SA3mPJDwKZiNgt6ZPA7cC0fVw22xhxM3AzQFVVVUydOvVtF2wl7j8ewr8/ZlYU3v/YEMjHYdmtwISc6fHAttwOEfFyROxOJm8B3ruvy5qZmZnZvstHuPsJMEnSCZKGAx8FluV2kHRMzuRsoDV5vxyYKWl0ciHFzKTNzMzMzN6GQR+WjYh2SfPJhrIy4NaIWC/pa8CaiFgGfEbSbKAd2A58PFl2u6T/j2xABPhaRGwfbE1mZmZmpSovNzGOiIeBh3u1fSnn/QJgQT/L3grcmo86zMzMzEqdHz9mZmZmliIOd2ZmZmYp4nBnZmZmliIOd2ZmZmYp4nBnZmZmliIOd2ZmZmYp4nBnZmZmliIOd2ZmZmYp4nBnZmZmliIOd2ZmZmYp4nBnZmZmliIOd2ZmZmYp4nBnZmZmliIOd2ZmZmYp4nBnZmZmliIOd2ZmZmYp4nBnZmZmliIOd2ZmZmYp4nBnZmZmliIOd2ZmZmYp4nBnZmZmliIOd2ZmZmYp4nBnZmZmliIOd2ZmZmYp4nBnZmZmliIOd2ZmZmYpUl7sAsz684dffZTftr1ZkHUff+VDeV3fESMO4qkvz8zrOs3MzN4Ohzt7x/pt25tsuvrcvK+3paWFqVOn5nWd+Q6LZmZmb1deDstK+pCkn0naKOnKPuZ/VtIGSU9LapJ0XM68DklPJq9l+ajHzMzMrFQNeuROUhlwEzAD2Ar8RNKyiNiQ0+0JoCoi3pA0D7gWOD+Z1xYRpw62DjMzMzPLz8jd+4GNEfFsROwB7gbm5HaIiOaIeCOZ/BEwPg/bNTMzM7Ne8nHO3ThgS870VuD0AfrXAo/kTB8iaQ3QDlwdEQ/0tZCky4DLAMaOHUtLS8tgarYDRCH+O+/YsaMg6/XvpJntC+8rrNDyEe7UR1v02VH6a6AK+EBO88SI2CbpPcBKSWsj4hdvWWHEzcDNAFVVVZHvE+LtHeg/Hsr7hQ9QmAsqClWrmaWM9xU2BPJxWHYrMCFnejywrXcnSR8E6oHZEbG7qz0itiU/nwVagNPyUJOZmZlZScpHuPsJMEnSCZKGAx8Felz1Kuk04F/JBrvf5LSPlnRw8v4o4Ewg90IMMzMzM9sPgz4sGxHtkuYDy4Ey4NaIWC/pa8CaiFgGXAeMBO6VBLA5ImYDFcC/SuokGzSv7nWVrZmZmZnth7zcxDgiHgYe7tX2pZz3H+xnudXAyfmowczMzMz8hAozM7O38OMP7UDmcGdmZtaLH39oB7K8PH7MzMzMzN4ZHO7MzMzMUsThzszMzCxFHO7MzMzMUsThzszMzCxFHO7MzMzMUsThzszMzCxFHO7MzMzMUsThzszMzCxFHO7MzMzMUsThzszMzCxFHO7MzMzMUsThzszMzCxFHO7MzMzMUsThzszMzCxFHO7MzMzMUsThzszMzCxFHO7MzMzMUsThzszMzCxFHO7MzMzMUsThzszMzCxFHO7MzMzMUsThzszMzCxFHO7MzMzMUsThzszMzCxFHO7MzMzMUiQv4U7ShyT9TNJGSVf2Mf9gSfck838s6ficeQuS9p9JmpWPeszMzMxK1aDDnaQy4CbgbGAyUCNpcq9utcArEXEicANwTbLsZOCjwEnAh4BFyfrMzMzM7G3Ix8jd+4GNEfFsROwB7gbm9OozB7g9eX8fMF2Skva7I2J3RDwHbEzWZ2ZmZmZvQ3ke1jEO2JIzvRU4vb8+EdEu6bfAkUn7j3otO66vjUi6DLgMYOzYsbS0tOShdHsnO7ziSk6+/S1H+fPj9r132R+HV0BLy2H5XamZFY33P3Ygy0e4Ux9tsY999mXZbGPEzcDNAFVVVTF16tT9KNEORGtZW5D1Hn/lQ2y6+tyCrNvM0sH7HzuQ5eOw7FZgQs70eGBbf30klQNHANv3cVkzMzMz20f5CHc/ASZJOkHScLIXSCzr1WcZcFHy/jxgZURE0v7R5GraE4BJwH/noSYzMzOzkjTow7LJOXTzgeVAGXBrRKyX9DVgTUQsAxqBb0vaSHbE7qPJsuslfQfYALQDn46IjsHWZGZmZlaq8nHOHRHxMPBwr7Yv5bzfBXy4n2UbgIZ81GFmZmZW6vyECjMzM7MUcbgzMzMzSxGHOzMzM7MUcbgzMzMzSxGHOzMzM7MUcbgzMzMzSxGHOzMzM7MUcbgzMzMzSxGHOzMzM7MUcbgzMzMzSxGHOzMzM7MUcbimG5XpAAAdZ0lEQVQzMzMzSxGHOzMzM7MUcbgzMzMzSxGHOzMzM7MUcbgzMzMzSxGHOzMzM7MUcbgzMzMzSxGHOzMzM7MUcbgzMzMzSxGHOzMzM7MUcbgzMzMzSxGHOzMzM7MUcbgzMzMzSxGHOzMzM7MUcbgzMzMzSxGHOzMzM7MUcbgzMzMzS5FBhTtJYyStkPRM8nN0H31OlfRfktZLelrS+TnzbpP0nKQnk9epg6nHzMzMrNQNduTuSqApIiYBTcl0b28AfxMRJwEfAv5Z0qic+f8QEacmrycHWY+ZmZlZSRtsuJsD3J68vx2Y27tDRPw8Ip5J3m8DfgMcPcjtmpmZmVkfyge5/NiIeAEgIl6Q9O6BOkt6PzAc+EVOc4OkL5GM/EXE7n6WvQy4DGDs2LG0tLQMsnQrZf79MbNi8f7HCm2v4U7S94Hf6WNW/f5sSNIxwLeBiyKiM2leAPyKbOC7Gfg88LW+lo+Im5M+VFVVxdSpU/dn82b/6z8ewr8/ZlYU3v/YENhruIuID/Y3T9KvJR2TjNodQ/aQa1/93gU8BHwxIn6Us+4Xkre7JX0L+Nx+VW9mZmZmPQz2nLtlwEXJ+4uApb07SBoO3A/cERH39pp3TPJTZM/XWzfIeszMzMxK2mDD3dXADEnPADOSaSRVSfpm0ucjwFnAx/u45cmdktYCa4GjgK8Psh4zMzOzkjaoCyoi4mVgeh/ta4BLkvf/BvxbP8tPG8z2zczMzKwnP6HCzMzMLEUc7szMzAosk8lQWVnJL6+dTWVlJZlMptglWYoN9j53ZmZmNoBMJkN9fT2NjY18/OHXWHjOu6itrQWgpqamyNVZGikiil3Dfquqqoo1a9YUuww7QB1/5UNsuvrcYpdhZimRveFDYRyI/4+2wpH0eERU7a2fR+7MzMwGYW8BbNiwYRx//PE0NjbS0dFBWVkZtbW1bNq0ic7OzgGXNXs7HO7MzMwKaPjw4ZxxxhnU1dXR2tpKRUUFZ5xxBtu2bSt2aZZSDndmZmYFtHv3bjKZDEcffTQRwUsvvUQmk/GonRWMr5Y1MzMroPLyckaMGMGIESMAut+Xl3t8xQrDv1lmZmYF1N7ezpFHHsmtt97afc5dTU0NO3fuLHZpllIeuTMzMyuwiy++mLq6OmbNmkVdXR0XX3xxsUuyFHO4MzMzK6Dx48ezZMkSdu7cSUSwc+dOlixZwvjx44tdmqWUw52ZmVkBzZ07l9dee41du3YhiV27dvHaa68xd+7cYpdmKeVwZ2ZmVkDNzc0sWLCAI488EoAjjzySBQsW0NzcXOTKLK0c7szMzAqotbWV7du3s3HjRjo7O9m4cSPbt2+ntbW12KVZSvlqWTMzswIaNWoUN998M9deey2TJ09mw4YNXHHFFYwaNarYpVlKOdyZmZkV0Guvvca73vUuTjvtNDo6OjjttNN417vexWuvvVbs0iylHO7MzMwKqL29nW984xs9Hj/2jW98g0984hPFLs1SyufcWcnIZDJUVlbyy2tnU1lZSSaTKXZJZlYCDj74YJqamnq0NTU1cfDBBxepIks7hzsrCZlMhvr6ehYuXMjEv/8uCxcupL6+3gHPzAruAx/4AHfeeSdnnXUWS5cu5ayzzuLOO+/kAx/4QLFLs5RSRBS7hv1WVVUVa9asKXYZ9g4iqWDrPhD/jZjZO0dlZSWTJk3ikUceYffu3Rx88MGcffbZPPPMM6xbt67Y5dkBRNLjEVG1t34+585SYW8BrKysjF27dnHQQQfR0tLC1KlTefPNNznkkEPo6OgYoirNrBS1trbyxBNP9Ln/MSsEH5a1klBRUcGqVat6tK1atYqKiooiVWRmpcL7HxtqDndWEurr66mtraW5uZn29naam5upra2lvr6+2KWZWcp5/2NDzYdlrSTU1NSwevVqzj777O5zXi699FJqamqKXZqZpVzXfib3VigNDQ3e/1jBONxZSchkMjz00EM88sgjdHR0UFZWRm1tLWeccYZ3sGZWcDU1NdTU1HSfc2dWSD4sayWhoaGBxsZGqqurKS8vp7q6msbGRhoaGopdmpmZWV453FlJaG1tZcqUKT3apkyZ4gd3m5lZ6gzqsKykMcA9wPHAJuAjEfFKH/06gLXJ5OaImJ20nwDcDYwBfgp8LCL2DKYms75UVFQwfPjwt7SfdNJJRajGzErNsGHDetyySRKdnZ1FrMjSbLAjd1cCTRExCWhKpvvSFhGnJq/ZOe3XADcky78C1A6yHrM+rV+/HsjuYK+77jqGDRvWo93MrFC6gt0hhxzCjTfeyCGHHEJEdO+HzPJtsL9Zc4Dbk/e3A3P3dUFlHykwDbjv7Sxvtr+GDRtGRUUFn//856moqPCO1cyGRFewa2tr46STTqKtra074JkVwmCvlh0bES8ARMQLkt7dT79DJK0B2oGrI+IB4Ejg1YhoT/psBcb1tyFJlwGXAYwdO5aWlpZBlm6l5vrrr+e0005jx44djBw5kieeeILPfvaz/l0ys4K7/vrraWlpYceOHbS0tHD99dczf/5873+sIPb6bFlJ3wd+p49Z9cDtETEqp+8rETG6j3UcGxHbJL0HWAlMB14D/isiTkz6TAAejoiT91a0ny1r+0sSZWVltLe3d9+KoLy8nI6ODv/1bGYFJal75K5r/zNixAh27drl/Y/tl319tuxej0tFxAcjorKP11Lg15KOSTZ4DPCbftaxLfn5LNACnAa8BIyS1DV6OB7Ytg+fzext6ejooLy8nCeeeKI72JmZFZokdu3axYgRI1i/fn13sMuenWSWf4M96WgZcFHy/iJgae8OkkZLOjh5fxRwJrAhsn+uNAPnDbS8WT50/XXc0dHBZz/72e5g57+azazQOjs7uwPe/Pnzu4Odr5a1QhlsuLsamCHpGWBGMo2kKknfTPpUAGskPUU2zF0dERuSeZ8HPitpI9lz8BoHWY9ZvyKCiKC5ubn7vZnZUOjs7Oyx/3Gws0IaVLiLiJcjYnpETEp+bk/a10TEJcn71RFxckT8YfKzMWf5ZyPi/RFxYkR8OCJ2D+7jmPUvk8lQWVnJ9OnTqaysJJPJFLskMzOzvPOzZa0kZDIZ6uvraWxs7PFsWcDPljUzs1RxuLOS0NDQwAUXXEBdXR2tra1UVFRwwQUX0NDQ4HBnZmap4nBnJWHDhg288cYbbxm527RpU7FLM7MSkMlkaGho6P7jsr6+3n9YWsE43FlJGD58OPPnz6e6urr7PlPz58/nC1/4QrFLM7OU82khNtT8/CUrCXv27GHhwoU0NzfT3t5Oc3MzCxcuZM+ePcUuzcxSrqGhgcbGRqqrqykvL6e6uprGxkYaGhqKXZqllEfurCRMnjyZuXPn9jjn7sILL+SBBx4odmlmlnKtra1MmTKlR9uUKVNobW0tUkWWdg53VhLq6+upra2lra0NgPXr1/Pss8/S2OhbK5pZYVVUVDBu3DhefPHF7rajjz6aioqKIlZlaebDslYSbrvtNtra2hg9ejTDhg1j9OjRtLW1cdtttxW7NDNLuRdeeIEXX3yRk046iUwmw0knncSLL77ICy+8UOzSLKUc7qwkrFixgnnz5rF9+3aamprYvn078+bNY8WKFcUuzcxSbvv27UyaNAmACy+8EIBJkyaxffv2YpZlKeZwZyUhIrjqqqt6tF111VV+BJmZDYkf/OAHrFu3jqamJtatW8cPfvCDYpdkKeZwZyVBEpWVlQwbNozq6mqGDRtGZWUlkopdmpmVgPPOO2/AabN8crizkjB69Gi2bt3K5MmTyWQyTJ48ma1btzJ69Ohil2ZmKTdhwgRWr17NoYceyrRp0zj00ENZvXo1EyZMKHZpllIOd1YSXnnlFcaPH8+GDRuoqalhw4YNjB8/nldeeaXYpZlZyl1zzTWUlZXR1tZGRNDW1kZZWRnXXHNNsUuzlHK4s5IQEaxbt47Ozk6am5vp7Oxk3bp1PufOzAquoaGBFStWEBE0NzcTEaxYscI3MbaCcbizkiCJBQsW9GhbsGCBz7kzs4LzTYxtqDncWUmYMWMGixcv5lOf+hQ7duzgU5/6FIsXL2bGjBnFLs3MUq6iooJVq1b1aFu1apVvYmwF4ydUWElYvnw5s2bNYsmSJSxevBhJzJw5k+XLlxe7NDNLufr6es4//3wOO+wwfvnLX3Lcccexc+dO/uVf/qXYpVlKOdxZyegKci0tLUydOrW4xZhZSfKpIDYUfFjWzMysgBoaGrjnnnt47rnnaGpq4rnnnuOee+7xBRVWMA53VjIymQyVlZVMnz6dyspKMplMsUsysxLgCypsqPmwrJWETCZDfX09jY2NdHR0UFZWRm1tLQA1NTVFrs7M0qzrgorq6uruNl9QYYWkA/E+X1VVVbFmzZpil2EHkMrKSkaMGMHjjz9ORCCJ9773vbS1tbFu3bpil2dmKZbJZKitraWtra27bcSIETQ2NvqPS9svkh6PiKq99fNhWSsJ69evZ82aNXzyk5/kwQcf5JOf/CRr1qxh/fr1xS7NzFLutttuo62tjdGjRzNs2DBGjx5NW1sbt912W7FLs5RyuLOSMXv2bBYtWsTIkSNZtGgRs2fPLnZJZlYCVqxYwbx589i+fTtNTU1s376defPmsWLFimKXZinlcGcl46mnnqK5uZn29naam5t56qmnil2SmZWAiOCqq67q0XbVVVf58YdWMA53VhIkceKJJ1JXV8esWbOoq6vjxBNP9D2nzKzg/PhDG2oOd1YSZsyYQVNTE2eddRZLly7lrLPOoqmpyY8fM7OC8+MPbaj5alkrGbNmzWLFihXdV8vOmDHDjx8zsyHh/Y/lw5BcLStpjKQVkp5Jfo7uo0+1pCdzXrskzU3m3SbpuZx5pw6mHjMzs3ei5cuX09nZSXNzM52dnQ52VlCDPSx7JdAUEZOApmS6h4hojohTI+JUYBrwBvBoTpd/6JofEU8Osh6zPs2aNYtHH320x61QHn30UWbNmlXs0szMzPJqsOFuDnB78v52YO5e+p8HPBIRbwxyu2b7petWBLm3QvGtCMzMLI0Gdc6dpFcjYlTO9CsR8ZZDsznzVwL/FBHfS6ZvA/4E2E0y8hcRu/tZ9jLgMoCxY8e+9+67737bdVvpqa6u5sEHH2TkyJHs2LGj++ef//mf09zcXOzyzKxEdO1/zN6O6urqfTrnbq/PlpX0feB3+phVvz8FSToGOBnIPdFgAfArYDhwM/B54Gt9LR8RNyd9qKqqiqlTp+7P5q3ESeLhhx9m0aJFtLS0MHXqVD71qU8hCf8umdlQ6dr/mBXSXsNdRHywv3mSfi3pmIh4IQlvvxlgVR8B7o+IN3PW/ULydrekbwGf28e6zfZL160IAM4555zuWxHMnDmzyJWZmZnl117D3V4sAy4Crk5+Lh2gbw3ZkbpuOcFQZM/X8xPcrSCWL1/OrFmzWLJkCYsXL0YSM2fO9BVrZmaWOoO9oOJqYIakZ4AZyTSSqiR9s6uTpOOBCcAPei1/p6S1wFrgKODrg6zHrF++FYGZmZWCQYW7iHg5IqZHxKTk5/akfU1EXJLTb1NEjIuIzl7LT4uIkyOiMiL+OiJ2DKYes4FkMhkqKyuZPn06lZWVZDKZYpdkZiXC+x8bSoM9LGt2QMhkMtTX19PY2EhHRwdlZWXU1tYCUFNTU+TqzCzNvP+xoeZny1pJaGhooLGxkerqasrLy6murqaxsZGGhoZil2ZmKef9jw01hzsrCa2trUyZMqVH25QpU2htbS1SRWZWKrz/saHmcGcloaKiglWrVvVoW7VqFRUVFUWqyMxKhfc/NtQc7qwk1NfXU1tbS3NzM+3t7TQ3N1NbW0t9/X7di9vMbL95/2NDzRdUWEnoOmm5rq6O1tZWKioqaGho8MnMZlZw3v/YUBvUs2WLpaqqKtasWVPsMuwA5cf/mFmxeP9jgyFpn54t68OyZmZmZinicGdmZmaWIg53ZmZmZinicGdmZmaWIg53ZmZmZinicGdmZmaWIg53ZmZmBZbJZKisrGT69OlUVlaSyWSKXZKlmG9ibGZmVkCZTIb6+noaGxvp6OigrKyM2tpaAN/I2ArCI3dmZmYF1NDQQGNjI9XV1ZSXl1NdXU1jYyMNDQ3FLs1SyuHOzMysgFpbW5kyZUqPtilTptDa2lqkiiztHO7MzMwKqKKiglWrVvVoW7VqFRUVFUWqyNLO4c7MzKyA6uvrqa2tpbm5mfb2dpqbm6mtraW+vr7YpVlK+YIKMzOzAuq6aKKuro7W1lYqKipoaGjwxRRWMA53ZmZmBVZTU0NNTQ0tLS1MnTq12OVYyvmwrJmZmVmKONyZmZmZpYjDnZmZmVmKONyZmZmZpYjDnZmZmVmKONyZmZmZpYjDnZmZmVmKDCrcSfqwpPWSOiVVDdDvQ5J+JmmjpCtz2k+Q9GNJz0i6R9LwwdRjNpBTTjkFSVRXVyOJU045pdglmVmJmDhxYo/9z8SJE4tdkqXYYEfu1gF/Cfywvw6SyoCbgLOByUCNpMnJ7GuAGyJiEvAKUDvIesz6dMopp7B27Vpmz57N/fffz+zZs1m7dq0DnpkV3MSJE9myZQtnnHEG9957L2eccQZbtmxxwLOCGVS4i4jWiPjZXrq9H9gYEc9GxB7gbmCOJAHTgPuSfrcDcwdTj1l/uoLd0qVLGTVqFEuXLu0OeGZmhdQV7B577DGOOuooHnvsse6AZ1YIQ/H4sXFA7m/wVuB04Ejg1Yhoz2kf199KJF0GXAYwduxYWlpaClKspdfFF19MS0sLO3bsoKWlhYsvvphly5b5d8nMCu7yyy/vsf+5/PLLWb16tfc/VhB7DXeSvg/8Th+z6iNi6T5sQ320xQDtfYqIm4GbAaqqqsLP5rP99a1vfYulS5d2P9txzpw5AH7Oo5kV3A033MBjjz3Wvf8588wzAe9/rDD2elg2Ij4YEZV9vPYl2EF2RG5CzvR4YBvwEjBKUnmvdrO8O/nkk1m2bBlz5szh1VdfZc6cOSxbtoyTTz652KWZWcpNmDCB1atXc+aZZ/LSSy9x5plnsnr1aiZMmLD3hc3eBkX0O1i27yuRWoDPRcSaPuaVAz8HpgPPAz8BLoiI9ZLuBf49Iu6WtAR4OiIW7W17VVVVsWbNWzZlNqCuiyq6nHzyyTz99NNFrMjMSkXXRRVdJkyYwObNm4tYkR2IJD0eEf3enaTLYG+F8heStgJ/AjwkaXnSfqykhwGSc+rmA8uBVuA7EbE+WcXngc9K2kj2HLzGwdRjNpCnn36aiKC5uZmIcLAzsyGzefPmHvsfBzsrpEFdUBER9wP399G+DTgnZ/ph4OE++j1L9mpaMzMzM8sDP6HCzMzMLEUc7szMzMxSxOHOzMzMLEUc7szMzMxSxOHOzMzMLEUc7szMzMxSxOHOzMzMLEUc7szMzMxSxOHOzMzMLEXy8mzZoSbpReCXxa7DDlhHAS8VuwgzK0ne/9hgHBcRR++t0wEZ7swGQ9KafXnwsplZvnn/Y0PBh2XNzMzMUsThzszMzCxFHO6sFN1c7ALMrGR5/2MF53PuzMzMzFLEI3dmZmZmKeJwZ2ZmZpYiDndWEJI6JD0pab2kpyR9VlLef98ktUh6y20FJH1c0o372p4z/+Sk7iclbZf0XPL++/mu3cyKQ1JI+kbO9OckfaUIdXxF0vPJPmadpNl76T/g/muA5aok/b+3X6kdaMqLXYClVltEnAog6d3AXcARwJeLWtVeRMRaoKvu24DvRcR9vftJKo+I9iEuz8zyYzfwl5Kuiohi31D4hoi4XlIF8J+S3h0RnfncQESsAdbkc532zuaROyu4iPgNcBkwX1mHSPqWpLWSnpBUDd1/lX5X0n9IekbStV3rkLRY0ppkJPCrfW1H0sWSfi7pB8CZ+f4ckj4o6fuS7gaekHSipCdz5l8p6YvJ+1WS/knSf0rakPzlfH/yub6S9Dkx+TzfTr6L70gake+6zewt2sletXp57xmS/lzSj5N90/cljU3avyLp1uRowbOSPpOzzN9Iejo5SvFtSYcno/4HJfPfJWlT13RfIqI1qesoSUdL+ndJP0leb9mfSTpOUlOy3SZJE5P2DyejgE9J+mHSNlXS9wb3ldmBxOHOhkREPEv29+3dwKeTtpOBGuB2SYckXU8FzgdOBs6XNCFpr0/u6n4K8AFJp+SuX9IxwFfJhroZwOQCfZQ/Bq5Iat+btoj4U6AReAD4JNnPdZmkUUmfycBNyfp2AX9bgJrN7K1uAi6UdESv9lXAH0fEacDdwBU58/4AmAW8H/iypIMknQTUA9Mi4g+Bv4uI14EW4NxkuY8C/x4Rb/ZXjKTTgU7gReBfyI7ovQ/4K+CbfSxyI3BHRJwC3Al0HXb9EjArqWXAw7yWXg53NpSU/JwCfBsgIv6H7HOCfy+Z1xQRv42IXcAG4Lik/SOSfgo8AZzEW8Pb6UBLRLwYEXuAewr0Gf4rIjbvY99lyc+1wNqI+HXyuTYB45N5z0XEj5L3/0b2uzGzAouI14A7gM/0mjUeWC5pLfAPZPc3XR6KiN3JodzfAGOBacB9XYd3I2J70vebwMXJ+4uBb/VTyuXJEYDrgfMje3+yDwI3Ju3LgHdJOrzXcn9C9nQXyO5Pu/YdjwG3SboUKNvL12Ap5XPubEhIeg/QQXaHqAG67s553wGUSzoB+Bzwvoh4JTkX7pA+lh2KmzbuzHnfTs8/kA5J2rp0fZZOen6uTv73317vmn3jSbOh88/AT+kZvBYC/xQRyyRNBb6SM+8t+yey+7O3/LuNiMckHS/pA0BZRKzrp4YbIuL6Xm3DgD+JiLbcRmmgXWe2hoj4ZDIKeC7wpKRTB1rI0skjd1Zwko4GlgA3Jn+V/hC4MJn3e8BE4GcDrOJdZEPVb5PzX87uo8+PgamSjkzOa/lwHj9Cf34FHCtpdHJY+dy9LdCHEyS9L3lfQ/aQkJkNgWSU7TtAbU7zEcDzyfuL9mE1TWSPLBwJIGlMzrw7gAz9j9r151FgftdEPwFtNdnDvZDdn65K+v5uRPw4Ir4EvARM6GNZSzmHOyuUEUpuhQJ8n+zOqutCiEVAWXLY4x7g4xGxu5/1EBFPkT0cux64lexhh959XiD7F/Z/Jdv7aT+rKyf561vSbElf2/+P1r3NXcA/Aj8he+hkw9tYzXrgUklPA4fhRxOZDbVvAEflTH8FuFfSf5INRwOKiPVAA/ADSU8B/5Qz+05gNNmAtz8+A1QlF0tsIHu+bl99Lk72HR8D/i5pvy65QGsd2T+kn9rPbVsK+PFjVlIk3QA8ExGL3gG1nEj2XB0fNjFLIUnnAXMi4mPFrsVKi8+5s5Ih6RFgOD3PoTEzyztJC8meQnJOsWux0uOROzMzM7MU+f/bu3fWKqIoDMPvR1BJiGAhQjobFbwgiIIoiIpYWSg2io1N/oB17CysRSubdCnES2OhgqDgDS8YxAgWio0WNv6BuCzORo7hROMlFnPep9psFrNnuo89M3v5zZ0kSVKHGO4kSZI6xHAnSZLUIYY7SUOlHSy72IGyf3Pd6fZ3JK3/6M5/vYYkLYXhTpIkqUMMd5KG0UiSy0leJ7mdZDTJZJKnSWaTXE0yBt935C4keZjkXd/uXJJcTDKX5CawbtBCSQ4neZTkRZIrScb/43NKGkKGO0nDaANwqaq2AF+A48C1qtpVVduBN/zYkmqCXmP2I8D5NncM2ARsAyaBPQsXSbIWmAIOVdUO4BlwZlmeSJIaDzGWNIzeV9XLNn4OrAe2JjkHrAHGgVt99Teq6isw1/obA+wDZqpqHviY5O6AdXYDm4EHren7Snot8iRp2RjuJA2j/l7G88AoMA0crarZJKeB/YvUp2/8q1PgA9ypqpN/fKeS9Jt8LStJPauBT0lWAKeWUH8fOJFkJMkEcGBAzWNgb+sjTJKxJBv/2R1L0gDu3ElSz1ngCfABeEUv7P3MdeBgq30L3FtYUFWf2y7gTJJVbXqq1UvSsrC3rCRJUof4WlaSJKlDDHeSJEkdYriTJEnqEMOdJElShxjuJEmSOsRwJ0mS1CGGO0mSpA75BreOb+QYgP3mAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create box plots\n",
    "# Note: column: used to limit data to a subset of columns\n",
    "#       by: used to form box plots for separate groups\n",
    "#       figsize: a tuple (width, height) in inches\n",
    "tweets.boxplot(column='sentiment', by='handle', figsize=(10, 6));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>handle</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>KEEP AMERICA GREAT!</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>MAKE AMERICA GREAT AGAIN!</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>Heading now to the Great State of Alabama!</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>Thank you @foxandfriends. Great show!</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>The greatest overreach in the history of our C...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              handle                                               text  \\\n",
       "10   Donald J. Trump                                KEEP AMERICA GREAT!   \n",
       "11   Donald J. Trump                          MAKE AMERICA GREAT AGAIN!   \n",
       "97   Donald J. Trump         Heading now to the Great State of Alabama!   \n",
       "105  Donald J. Trump              Thank you @foxandfriends. Great show!   \n",
       "131  Donald J. Trump  The greatest overreach in the history of our C...   \n",
       "\n",
       "     sentiment  \n",
       "10         1.0  \n",
       "11         1.0  \n",
       "97         1.0  \n",
       "105        1.0  \n",
       "131        1.0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tweets with most positive sentiment\n",
    "tweets[tweets.sentiment == 1][['handle', 'text', 'sentiment']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>handle</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>One year ago today, a horrific act of violence...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>Any deaths of children or others at the Border...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>...sleazebag AG Eric Schneiderman, who has sin...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>....She will probably be given a pass, despite...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>Nancy Pelosi</td>\n",
       "      <td>.@realDonaldTrump’s revival of his bigoted, di...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               handle                                               text  \\\n",
       "325   Donald J. Trump  One year ago today, a horrific act of violence...   \n",
       "808   Donald J. Trump  Any deaths of children or others at the Border...   \n",
       "907   Donald J. Trump  ...sleazebag AG Eric Schneiderman, who has sin...   \n",
       "961   Donald J. Trump  ....She will probably be given a pass, despite...   \n",
       "1009     Nancy Pelosi  .@realDonaldTrump’s revival of his bigoted, di...   \n",
       "\n",
       "      sentiment  \n",
       "325        -1.0  \n",
       "808        -1.0  \n",
       "907        -1.0  \n",
       "961        -1.0  \n",
       "1009       -1.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reviews with most negative sentiment\n",
    "tweets[tweets.sentiment == -1][['handle', 'text', 'sentiment']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Widen the column display\n",
    "pd.set_option('max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>handle</th>\n",
       "      <th>mined_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>trump_handle</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Wed Mar 13 11:39:13 +0000 2019</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2019-03-13 14:16:12.087980</td>\n",
       "      <td>16336</td>\n",
       "      <td>Defying voters, the Governor of California will halt all death penalty executions of 737 stone cold killers. Friend… https://t.co/GEITgYJNdY</td>\n",
       "      <td>1105795445794717697</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at           handle                   mined_at  \\\n",
       "9  Wed Mar 13 11:39:13 +0000 2019  Donald J. Trump 2019-03-13 14:16:12.087980   \n",
       "\n",
       "   retweet_count  \\\n",
       "9          16336   \n",
       "\n",
       "                                                                                                                                           text  \\\n",
       "9  Defying voters, the Governor of California will halt all death penalty executions of 737 stone cold killers. Friend… https://t.co/GEITgYJNdY   \n",
       "\n",
       "              tweet_id  trump_handle  sentiment  \n",
       "9  1105795445794717697             1       -0.6  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Negative sentiment in a Trump tweet\n",
    "tweets[(tweets.handle == 'Donald J. Trump') & (tweets.sentiment < -0.3)].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>handle</th>\n",
       "      <th>mined_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>trump_handle</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>Wed Mar 13 20:33:51 +0000 2019</td>\n",
       "      <td>Nancy Pelosi</td>\n",
       "      <td>2019-03-13 14:16:22.440601</td>\n",
       "      <td>178</td>\n",
       "      <td>Looking forward to my conversation with President @KerstiKaljulaid of Estonia today. Tune in as I welcome her to th… https://t.co/VO7qbHgq4T</td>\n",
       "      <td>1105929991852826627</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          created_at        handle                   mined_at  \\\n",
       "1000  Wed Mar 13 20:33:51 +0000 2019  Nancy Pelosi 2019-03-13 14:16:22.440601   \n",
       "\n",
       "      retweet_count  \\\n",
       "1000            178   \n",
       "\n",
       "                                                                                                                                              text  \\\n",
       "1000  Looking forward to my conversation with President @KerstiKaljulaid of Estonia today. Tune in as I welcome her to th… https://t.co/VO7qbHgq4T   \n",
       "\n",
       "                 tweet_id  trump_handle  sentiment  \n",
       "1000  1105929991852826627             0        0.8  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Positive sentiment in a Pelosi tweet\n",
    "tweets[(tweets.handle == 'Nancy Pelosi') & (tweets.sentiment > 0.5)].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the column display width\n",
    "pd.reset_option('max_colwidth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using NLP Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build and train text classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: There are website links in the tweets.<br>\n",
    "Using the textacy package to do more comprehensive preprocessing before building model\n",
    "(http://textacy.readthedocs.io/en/latest/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_text = tweets.text.values\n",
    "\n",
    "# Normalize various aspects of a raw text doc before parsing it with Spacy\n",
    "# -> A convenience function for applying all other preprocessing functions in one go\n",
    "# Note: fix_unicode: if True, fix \"broken\" unicode such as mojibake and garbled HTML entities\n",
    "#       lowercase: if True, all text is lower-cased\n",
    "#       transliterate: if True, convert non-ascii characters into their closest ascii equivalents\n",
    "#       no_urls: if True, replace all URL strings with '*URL*'\n",
    "#       no_emails: if True, replace all email strings with '*EMAIL*'\n",
    "#       no_phone_numbers: if True, replace all phone number strings with '*PHONE*'\n",
    "#       no_currency_symbols: if True, replace all currency symbols with their standard 3-letter abbreviations\n",
    "#       no_punct: if True, remove all punctuation (replace with empty string)\n",
    "#       no_accents: if True, replace all accented characters with unaccented versions; NB: if `transliterate` is True, this option is redundant\n",
    "clean_text = [preprocess_text(x, fix_unicode=True, lowercase=True, transliterate=False,\n",
    "                              no_urls=True, no_emails=True, no_phone_numbers=True, no_currency_symbols=True,\n",
    "                              no_punct=True, no_accents=True)\n",
    "              for x in tweet_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://t.co/2qWkPuFDL6'\n",
      " 'Republican Senators are overthinking tomorrow’s vote on National Emergency. It is very simply Border Security/No Cr… https://t.co/RuQzOUPmi3'\n",
      " 'Democrats will have a unanimous vote on a 20% issue in opposing Republican Senators tomorrow. The Dems are for Open Borders and Crime!']\n"
     ]
    }
   ],
   "source": [
    "print(tweet_text[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['url', 'republican senators are overthinking tomorrow s vote on national emergency it is very simply border security no cr url', 'democrats will have a unanimous vote on a 20 issue in opposing republican senators tomorrow the dems are for open borders and crime']\n"
     ]
    }
   ],
   "source": [
    "print(clean_text[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from a list\n",
    "clean_text_df = pd.DataFrame(clean_text, columns=['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>handle</th>\n",
       "      <th>mined_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>trump_handle</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wed Mar 13 18:54:10 +0000 2019</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2019-03-13 14:16:12.087965</td>\n",
       "      <td>6760</td>\n",
       "      <td>https://t.co/2qWkPuFDL6</td>\n",
       "      <td>1105904905888415744</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>url</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wed Mar 13 16:48:29 +0000 2019</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2019-03-13 14:16:12.087972</td>\n",
       "      <td>17361</td>\n",
       "      <td>Republican Senators are overthinking tomorrow’...</td>\n",
       "      <td>1105873274804813824</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>republican senators are overthinking tomorrow ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wed Mar 13 16:43:14 +0000 2019</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2019-03-13 14:16:12.087973</td>\n",
       "      <td>10777</td>\n",
       "      <td>Democrats will have a unanimous vote on a 20% ...</td>\n",
       "      <td>1105871954001739782</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>democrats will have a unanimous vote on a 20 i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wed Mar 13 14:28:54 +0000 2019</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2019-03-13 14:16:12.087974</td>\n",
       "      <td>4372</td>\n",
       "      <td>RT @GeraldoRivera: @SpeakerPelosi statements v...</td>\n",
       "      <td>1105838146057588737</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>rt geraldorivera speakerpelosi statements vs i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wed Mar 13 14:28:50 +0000 2019</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2019-03-13 14:16:12.087975</td>\n",
       "      <td>6436</td>\n",
       "      <td>RT @GeraldoRivera: As #RobertMueller approache...</td>\n",
       "      <td>1105838130685493248</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0625</td>\n",
       "      <td>rt geraldorivera as robertmueller approaches t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at           handle                   mined_at  \\\n",
       "0  Wed Mar 13 18:54:10 +0000 2019  Donald J. Trump 2019-03-13 14:16:12.087965   \n",
       "1  Wed Mar 13 16:48:29 +0000 2019  Donald J. Trump 2019-03-13 14:16:12.087972   \n",
       "2  Wed Mar 13 16:43:14 +0000 2019  Donald J. Trump 2019-03-13 14:16:12.087973   \n",
       "3  Wed Mar 13 14:28:54 +0000 2019  Donald J. Trump 2019-03-13 14:16:12.087974   \n",
       "4  Wed Mar 13 14:28:50 +0000 2019  Donald J. Trump 2019-03-13 14:16:12.087975   \n",
       "\n",
       "   retweet_count                                               text  \\\n",
       "0           6760                            https://t.co/2qWkPuFDL6   \n",
       "1          17361  Republican Senators are overthinking tomorrow’...   \n",
       "2          10777  Democrats will have a unanimous vote on a 20% ...   \n",
       "3           4372  RT @GeraldoRivera: @SpeakerPelosi statements v...   \n",
       "4           6436  RT @GeraldoRivera: As #RobertMueller approache...   \n",
       "\n",
       "              tweet_id  trump_handle  sentiment  \\\n",
       "0  1105904905888415744             1     0.0000   \n",
       "1  1105873274804813824             1     0.0000   \n",
       "2  1105871954001739782             1     0.0000   \n",
       "3  1105838146057588737             1     0.5000   \n",
       "4  1105838130685493248             1    -0.0625   \n",
       "\n",
       "                                          clean_text  \n",
       "0                                                url  \n",
       "1  republican senators are overthinking tomorrow ...  \n",
       "2  democrats will have a unanimous vote on a 20 i...  \n",
       "3  rt geraldorivera speakerpelosi statements vs i...  \n",
       "4  rt geraldorivera as robertmueller approaches t...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate DataFrames\n",
    "# Note: axis=0 for rows, axis=1 for columns\n",
    "tweets = pd.concat([tweets, clean_text_df], axis=1)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting Donald Trump tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    1000\n",
      "0    1000\n",
      "Name: trump_handle, dtype: int64\n",
      "\n",
      "Percentage of trump_handle=No(0), trump_handle=Yes(1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    0.5\n",
       "0    0.5\n",
       "Name: trump_handle, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Categorical column frequency\n",
    "# Returns counts of unique values in descending order (first element is the most frequently-occurring element)\n",
    "# Note: Excludes NA values by default\n",
    "print(tweets.trump_handle.value_counts(dropna=False))\n",
    "print()\n",
    "print('Percentage of trump_handle=No(0), trump_handle=Yes(1)')\n",
    "round(tweets.trump_handle.value_counts(dropna=False)/len(tweets), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: CLASSES ARE EQUALLY BALANCED!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of features\n",
    "feature_cols = ['clean_text', 'sentiment']\n",
    "\n",
    "# Create X and y\n",
    "X = tweets[feature_cols]\n",
    "y = tweets.trump_handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X and y into training and testing sets\n",
    "# Note: train_size: between 0.0 and 1.0 and represent the proportion of the dataset to include in the train split\n",
    "#       test_size: between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split\n",
    "#       random_state: the seed used by the random number generator\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.70, test_size=0.30, random_state=65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Baseline Accuracy\n",
    "https://machinelearningmastery.com/how-to-get-baseline-results-and-why-they-matter/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    710\n",
      "1    690\n",
      "Name: trump_handle, dtype: int64\n",
      "\n",
      "Most frequent class in training dataset: 0\n",
      "\n",
      "Baseline accuracy: 0.483\n"
     ]
    }
   ],
   "source": [
    "# Categorical column frequency\n",
    "# Returns counts of unique values in descending order (first element is the most frequently-occurring element)\n",
    "# Note: Excludes NA values by default\n",
    "print(y_train.value_counts())\n",
    "print()\n",
    "\n",
    "most_freq_class = y_train.value_counts().index[0]\n",
    "print('Most frequent class in training dataset:', most_freq_class)\n",
    "print()\n",
    "\n",
    "print('Baseline accuracy:', round(y_test.value_counts()[most_freq_class] / y_test.count(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[CountVectorizer documentation](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use CountVectorizer with text column only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate CountVectorizer to convert a collection of text documents to a matrix of token counts\n",
    "# -> This implementation produces a sparse representation of the counts using scipy.sparse.csr_matrix\n",
    "vect = CountVectorizer()\n",
    "\n",
    "# Learn the vocabulary dictionary and return term-document matrix\n",
    "# -> This is equivalent to fit followed by transform, but more efficiently implemented\n",
    "X_train_dtm = vect.fit_transform(X_train.clean_text)\n",
    "\n",
    "# Transform documents to document-term matrix\n",
    "# -> Extract token counts out of raw text documents using the vocabulary fitted with fit or the one provided to the constructor\n",
    "X_test_dtm = vect.transform(X_test.clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 1400, Cols: 4541\n"
     ]
    }
   ],
   "source": [
    "# Return the number of rows (documents) and columns (terms (aka \"tokens\" or \"features\"; individual words in this situation)) of the DataFrame\n",
    "print('Rows: {}, Cols: {}'.format(X_train_dtm.shape[0], X_train_dtm.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 600, Cols: 4541\n"
     ]
    }
   ],
   "source": [
    "# Return the number of rows (documents) and columns (terms (aka \"tokens\" or \"features\"; individual words in this situation)) of the DataFrame\n",
    "print('Rows: {}, Cols: {}'.format(X_test_dtm.shape[0], X_test_dtm.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape of other feature columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 1400, Cols: 1\n"
     ]
    }
   ],
   "source": [
    "# Return the number of rows (documents) and columns (terms (aka \"tokens\" or \"features\"; individual words in this situation)) of the DataFrame\n",
    "print('Rows: {}, Cols: {}'.format(X_train.drop('clean_text', axis=1).shape[0], X_train.drop('clean_text', axis=1).shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 600, Cols: 1\n"
     ]
    }
   ],
   "source": [
    "# Return the number of rows (documents) and columns (terms (aka \"tokens\" or \"features\"; individual words in this situation)) of the DataFrame\n",
    "print('Rows: {}, Cols: {}'.format(X_test.drop('clean_text', axis=1).shape[0], X_test.drop('clean_text', axis=1).shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training set:<br>Cast other feature columns to float and convert to a sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1400x1 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 891 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compressed Sparse Row matrix\n",
    "extra = sp.sparse.csr_matrix(X_train.drop('clean_text', axis=1).astype(float))\n",
    "extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 1400, Cols: 1\n"
     ]
    }
   ],
   "source": [
    "# Return the number of rows (documents) and columns (terms (aka \"tokens\" or \"features\"; individual words in this situation)) of the DataFrame\n",
    "print('Rows: {}, Cols: {}'.format(extra.shape[0], extra.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 1400, Cols: 4542\n"
     ]
    }
   ],
   "source": [
    "# Combine sparse matrices\n",
    "# -> Stack sparse matrices horizontally (column wise)\n",
    "X_train_dtm_extra = sp.sparse.hstack((X_train_dtm, extra))\n",
    "\n",
    "# Return the number of rows (documents) and columns (terms (aka \"tokens\" or \"features\"; individual words in this situation)) of the DataFrame\n",
    "print('Rows: {}, Cols: {}'.format(X_train_dtm_extra.shape[0], X_train_dtm_extra.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing set:<br>Cast other feature columns to float and convert to a sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<600x1 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 365 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compressed Sparse Row matrix\n",
    "extra = sp.sparse.csr_matrix(X_test.drop('clean_text', axis=1).astype(float))\n",
    "extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 600, Cols: 1\n"
     ]
    }
   ],
   "source": [
    "# Return the number of rows (documents) and columns (terms (aka \"tokens\" or \"features\"; individual words in this situation)) of the DataFrame\n",
    "print('Rows: {}, Cols: {}'.format(extra.shape[0], extra.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 600, Cols: 4542\n"
     ]
    }
   ],
   "source": [
    "# Combine sparse matrices\n",
    "# -> Stack sparse matrices horizontally (column wise)\n",
    "X_test_dtm_extra = sp.sparse.hstack((X_test_dtm, extra))\n",
    "\n",
    "# Return the number of rows (documents) and columns (terms (aka \"tokens\" or \"features\"; individual words in this situation)) of the DataFrame\n",
    "print('Rows: {}, Cols: {}'.format(X_test_dtm_extra.shape[0], X_test_dtm_extra.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analyzer': 'word',\n",
       " 'binary': False,\n",
       " 'decode_error': 'strict',\n",
       " 'dtype': numpy.int64,\n",
       " 'encoding': 'utf-8',\n",
       " 'input': 'content',\n",
       " 'lowercase': True,\n",
       " 'max_df': 1.0,\n",
       " 'max_features': None,\n",
       " 'min_df': 1,\n",
       " 'ngram_range': (1, 1),\n",
       " 'preprocessor': None,\n",
       " 'stop_words': None,\n",
       " 'strip_accents': None,\n",
       " 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'tokenizer': None,\n",
       " 'vocabulary': None}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get parameters for this estimator\n",
    "vect.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['worth', 'would', 'wouldn', 'wounded', 'wow', 'write', 'writes', 'written', 'wrong', 'wrote', 'wsj', 'wsjopinion', 'xi', 'yahoo', 'ye', 'year', 'years', 'yemen', 'yes', 'yesterday', 'yet', 'yo', 'york', 'you', 'young', 'your', 'yourself', 'youtube', 'yr', 'yrs', 'zero', 'zinke', 'است', 'ایران', 'ترور', 'در', 'رنجند', 'رژیم', 'سال', 'سرکوب', 'شده', 'شکست', 'فساد', 'فقط', 'مدتهاست', 'مردم', 'موجب', 'چهل', 'که', '۴۰']\n"
     ]
    }
   ],
   "source": [
    "# Array mapping from feature integer indices to feature name\n",
    "# -> Last 50 features\n",
    "print(vect.get_feature_names()[-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features (unique words): 4541\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'virtually': 4321,\n",
       " 'everything': 1434,\n",
       " 'failed': 1493,\n",
       " 'lawyer': 2319,\n",
       " 'michael': 2528,\n",
       " 'cohen': 786,\n",
       " 'said': 3509,\n",
       " 'in': 2040,\n",
       " 'his': 1912,\n",
       " 'sworn': 3943,\n",
       " 'testimony': 4004,\n",
       " 'last': 2305,\n",
       " 'week': 4397,\n",
       " 'is': 2162,\n",
       " 'totally': 4093,\n",
       " 'contradicted': 921,\n",
       " 'url': 4254,\n",
       " 'republicans': 3378,\n",
       " 'continue': 915,\n",
       " 'to': 4078,\n",
       " 'be': 424,\n",
       " 'complicit': 841,\n",
       " 'realdonaldtrump': 3180,\n",
       " 'atrocities': 369,\n",
       " 'instead': 2103,\n",
       " 'of': 2744,\n",
       " 'standing': 3806,\n",
       " 'up': 4245,\n",
       " 'for': 1618,\n",
       " 'families': 1512,\n",
       " 'they': 4029,\n",
       " 'ar': 329,\n",
       " 'wishing': 4460,\n",
       " 'happy': 1828,\n",
       " 'birthday': 489,\n",
       " 'repjohnlewis': 3324,\n",
       " 'thank': 4011,\n",
       " 'you': 4514,\n",
       " 'all': 237,\n",
       " 'that': 4015,\n",
       " 'do': 1227,\n",
       " 'effect': 1317,\n",
       " 'change': 692,\n",
       " 'america': 267,\n",
       " 'rt': 3481,\n",
       " 'repjudychu': 3326,\n",
       " 'chanting': 695,\n",
       " 'broke': 572,\n",
       " 'out': 2804,\n",
       " 'the': 4016,\n",
       " 'capitol': 640,\n",
       " 'while': 4424,\n",
       " 'we': 4383,\n",
       " 'waited': 4350,\n",
       " 'introduce': 2137,\n",
       " 'dream': 1269,\n",
       " 'and': 277,\n",
       " 'promise': 3074,\n",
       " 'act': 144,\n",
       " 'finally': 1566,\n",
       " 'protect': 3090,\n",
       " 'dreamers': 1273,\n",
       " 'tp': 4103,\n",
       " 'mainstream': 2438,\n",
       " 'media': 2503,\n",
       " 'has': 1844,\n",
       " 'refused': 3230,\n",
       " 'cover': 970,\n",
       " 'fact': 1490,\n",
       " 'head': 1860,\n",
       " 'very': 4295,\n",
       " 'important': 2034,\n",
       " 'senate': 3602,\n",
       " 'intelligence': 2113,\n",
       " 'committe': 820,\n",
       " 'despite': 1150,\n",
       " 'repeal': 3308,\n",
       " 'netneutrality': 2673,\n",
       " 'will': 4444,\n",
       " 'not': 2709,\n",
       " 'stop': 3850,\n",
       " 'our': 2802,\n",
       " 'efforts': 1322,\n",
       " 'consumers': 911,\n",
       " 'savetheinternet': 3527,\n",
       " 'fr': 1648,\n",
       " 'message': 2523,\n",
       " 'if': 2005,\n",
       " 'your': 4516,\n",
       " 'daca': 1031,\n",
       " 'expired': 1473,\n",
       " 'on': 2764,\n",
       " 'or': 2789,\n",
       " 'after': 198,\n",
       " 'september': 3629,\n",
       " '2016': 39,\n",
       " 'may': 2481,\n",
       " 'submit': 3896,\n",
       " 'renewal': 3268,\n",
       " 'just': 2241,\n",
       " 'few': 1552,\n",
       " 'minutes': 2555,\n",
       " 'live': 2388,\n",
       " 'capehartj': 638,\n",
       " 'msnbc': 2611,\n",
       " 'amjoy': 273,\n",
       " 'discuss': 1201,\n",
       " 'housedemocrats': 1961,\n",
       " 'forthepeople': 1638,\n",
       " 'age': 203,\n",
       " 'restoring': 3407,\n",
       " 'american': 269,\n",
       " 'democracy': 1121,\n",
       " 'from': 1666,\n",
       " 'protecting': 3094,\n",
       " 'voting': 4339,\n",
       " 'rights': 3447,\n",
       " 'limiting': 2374,\n",
       " 'influence': 2076,\n",
       " 'money': 2580,\n",
       " 'ou': 2800,\n",
       " 'americans': 271,\n",
       " 'share': 3662,\n",
       " 'grief': 1781,\n",
       " 'tree': 4136,\n",
       " 'life': 2366,\n",
       " 'congregation': 879,\n",
       " 'pray': 3001,\n",
       " 'first': 1581,\n",
       " 'responders': 3399,\n",
       " 'who': 4433,\n",
       " 'rushed': 3494,\n",
       " 'into': 2134,\n",
       " 'democrats': 1124,\n",
       " 'are': 331,\n",
       " 'saying': 3532,\n",
       " 'worth': 4491,\n",
       " 'it': 2169,\n",
       " 'don': 1242,\n",
       " 'want': 4359,\n",
       " 'include': 2048,\n",
       " 'talks': 3959,\n",
       " 'many': 2458,\n",
       " 'hispanics': 1914,\n",
       " 'coming': 811,\n",
       " 'ov': 2811,\n",
       " 'repandybiggsaz': 3278,\n",
       " 'kate': 2246,\n",
       " 'steinle': 3827,\n",
       " 'sarah': 3522,\n",
       " 'root': 3472,\n",
       " 'grant': 1769,\n",
       " 'ronnebeck': 3471,\n",
       " 'willl': 4448,\n",
       " 'no': 2696,\n",
       " 'longer': 2400,\n",
       " 'bystanders': 605,\n",
       " 'these': 4028,\n",
       " 'crimes': 994,\n",
       " 'committed': 821,\n",
       " 'by': 604,\n",
       " 'illegal': 2010,\n",
       " 'alien': 233,\n",
       " 'care': 647,\n",
       " 'most': 2595,\n",
       " 'workers': 4480,\n",
       " 'getting': 1713,\n",
       " 'paid': 2834,\n",
       " 'shutdown': 3688,\n",
       " 'as': 348,\n",
       " 'soon': 3750,\n",
       " 'repvaldemings': 3379,\n",
       " 'two': 4184,\n",
       " 'years': 4507,\n",
       " 'pulse': 3120,\n",
       " 'know': 2279,\n",
       " 'love': 2415,\n",
       " 'win': 4450,\n",
       " 'transform': 4121,\n",
       " 'sorrow': 3752,\n",
       " 'progress': 3070,\n",
       " 'grieve': 1782,\n",
       " 'drug': 1281,\n",
       " 'prices': 3042,\n",
       " 'declined': 1085,\n",
       " '2018': 40,\n",
       " 'time': 4072,\n",
       " 'nearly': 2658,\n",
       " 'half': 1809,\n",
       " 'century': 672,\n",
       " 'during': 1287,\n",
       " '19': 24,\n",
       " 'months': 2585,\n",
       " 'my': 2629,\n",
       " 'administrat': 168,\n",
       " 'does': 1232,\n",
       " 'usa': 4256,\n",
       " 'policeman': 2955,\n",
       " 'middle': 2531,\n",
       " 'east': 1301,\n",
       " 'nothing': 2711,\n",
       " 'but': 599,\n",
       " 'spending': 3778,\n",
       " 'precious': 3007,\n",
       " 'lives': 2389,\n",
       " 'trillions': 4149,\n",
       " 'wall': 4356,\n",
       " 'street': 3863,\n",
       " 'journal': 2221,\n",
       " 'more': 2591,\n",
       " 'migrant': 2536,\n",
       " 'crossing': 1004,\n",
       " 'illegally': 2011,\n",
       " 'have': 1852,\n",
       " 'been': 435,\n",
       " 'arrested': 344,\n",
       " 'five': 1589,\n",
       " 'ending': 1362,\n",
       " 'trump': 4155,\n",
       " 'administration': 171,\n",
       " 'current': 1019,\n",
       " 'family': 1514,\n",
       " 'separation': 3627,\n",
       " 'policy': 2957,\n",
       " 'doesn': 1233,\n",
       " 'demand': 1113,\n",
       " 'trading': 4109,\n",
       " 'one': 2766,\n",
       " 'form': 1631,\n",
       " 'child': 720,\n",
       " 'abuse': 121,\n",
       " 'looking': 2403,\n",
       " 'forward': 1639,\n",
       " 'seeing': 3581,\n",
       " 'repbenraylujan': 3285,\n",
       " 'take': 3952,\n",
       " 'new': 2677,\n",
       " 'role': 3466,\n",
       " 'assistant': 358,\n",
       " 'leader': 2324,\n",
       " 'following': 1613,\n",
       " 'election': 1329,\n",
       " 'today': 4079,\n",
       " 'president': 3025,\n",
       " 'lady': 2293,\n",
       " 'melania': 2511,\n",
       " 'view': 4313,\n",
       " 'memorial': 2517,\n",
       " 'crosses': 1003,\n",
       " '23': 49,\n",
       " 'people': 2891,\n",
       " 'killed': 2265,\n",
       " 'alabama': 229,\n",
       " 'tornadoes': 4090,\n",
       " 'https': 1978,\n",
       " 'only': 2770,\n",
       " 'because': 430,\n",
       " '2020': 42,\n",
       " 'presidential': 3026,\n",
       " 'can': 626,\n",
       " 'based': 419,\n",
       " 'senator': 3606,\n",
       " 'rob': 3456,\n",
       " 'portman': 2973,\n",
       " 'cory': 948,\n",
       " 'gardner': 1690,\n",
       " 'early': 1294,\n",
       " 'warm': 4364,\n",
       " 'endorsement': 1364,\n",
       " 'together': 4080,\n",
       " 'mr': 2606,\n",
       " 'hope': 1944,\n",
       " 'near': 2657,\n",
       " 'future': 1681,\n",
       " 'mean': 2497,\n",
       " 'support': 3918,\n",
       " 'house': 1959,\n",
       " 'passed': 2855,\n",
       " 'package': 2832,\n",
       " 'endtheshutdown': 1366,\n",
       " 'harassment': 1832,\n",
       " 'with': 4463,\n",
       " 'great': 1772,\n",
       " 'sadness': 3506,\n",
       " 'learned': 2332,\n",
       " 'passing': 2856,\n",
       " 'dear': 1068,\n",
       " 'friend': 1663,\n",
       " 'former': 1634,\n",
       " 'joseph': 2220,\n",
       " 'tydings': 4186,\n",
       " 'prayers': 3002,\n",
       " 'repsarbanes': 3365,\n",
       " 'here': 1890,\n",
       " 'how': 1968,\n",
       " 'hr1': 1972,\n",
       " 'clean': 755,\n",
       " 'cultureofcorruption': 1013,\n",
       " 'washington': 4373,\n",
       " 'return': 3415,\n",
       " 'government': 1757,\n",
       " 'democratic': 1123,\n",
       " 'colleagues': 793,\n",
       " 'at': 367,\n",
       " 'pm': 2948,\n",
       " 'et': 1417,\n",
       " 'mark': 2465,\n",
       " 'six': 3712,\n",
       " 'since': 3706,\n",
       " 'their': 4021,\n",
       " 'christmas': 734,\n",
       " 'eve': 1425,\n",
       " 'plunging': 2946,\n",
       " 'country': 962,\n",
       " 'chaos': 696,\n",
       " 'stock': 3845,\n",
       " 'market': 2466,\n",
       " 'tanking': 3960,\n",
       " 'pre': 3004,\n",
       " 'repjayapal': 3319,\n",
       " 'look': 2402,\n",
       " 'this': 4036,\n",
       " 'list': 2383,\n",
       " 'existing': 1462,\n",
       " 'conditions': 860,\n",
       " 'chances': 691,\n",
       " 'll': 2391,\n",
       " 'identify': 2003,\n",
       " 'them': 4022,\n",
       " 'sco': 3553,\n",
       " 'prefers': 3010,\n",
       " 'alternative': 254,\n",
       " 'facts': 1492,\n",
       " 'tragedy': 4113,\n",
       " 'faced': 1487,\n",
       " 'lost': 2409,\n",
       " 'worse': 4489,\n",
       " 'still': 3842,\n",
       " 'go': 1731,\n",
       " 'tweet': 4181,\n",
       " 'tyler': 4187,\n",
       " 'houlton': 1955,\n",
       " 'spoxdhs': 3789,\n",
       " 'fakenews': 1502,\n",
       " 'being': 448,\n",
       " 'put': 3129,\n",
       " 'cnn': 780,\n",
       " 'proud': 3101,\n",
       " 'member': 2513,\n",
       " 'opposi': 2783,\n",
       " 'rephankjohnson': 3317,\n",
       " 'yesterday': 4510,\n",
       " 'joined': 2213,\n",
       " 'fellow': 1546,\n",
       " 'georgia': 1706,\n",
       " 'legislators': 2347,\n",
       " 'governor': 1758,\n",
       " 'emergency': 1347,\n",
       " 'declaration': 1081,\n",
       " 'request': 3384,\n",
       " 'lan': 2295,\n",
       " 'holding': 1927,\n",
       " 'paychecks': 2879,\n",
       " '800': 99,\n",
       " '000': 1,\n",
       " 'hostage': 1951,\n",
       " 'there': 4026,\n",
       " 'reason': 3185,\n",
       " 'suffe': 3908,\n",
       " 'encouraged': 1356,\n",
       " 'hear': 1869,\n",
       " 'courts': 969,\n",
       " 'delay': 1104,\n",
       " 'release': 3251,\n",
       " 'plans': 2934,\n",
       " '3d': 69,\n",
       " 'printed': 3048,\n",
       " 'firearms': 1575,\n",
       " 'would': 4492,\n",
       " 'death': 1069,\n",
       " 'massive': 2475,\n",
       " 'humanitarian': 1981,\n",
       " 'crisis': 997,\n",
       " 'southern': 3760,\n",
       " 'border': 530,\n",
       " 'long': 2398,\n",
       " 'unless': 4231,\n",
       " 'honor': 1940,\n",
       " 'constitutionday': 907,\n",
       " 'blocking': 508,\n",
       " 'congress': 880,\n",
       " 'performing': 2897,\n",
       " 'constitutiona': 903,\n",
       " 'was': 4372,\n",
       " 'campaign': 623,\n",
       " 'contribution': 925,\n",
       " 'were': 4410,\n",
       " 'violations': 4318,\n",
       " 'finance': 1568,\n",
       " 'laws': 2317,\n",
       " 'me': 2494,\n",
       " 'fake': 1500,\n",
       " 'news': 2681,\n",
       " 'speakerryan': 3769,\n",
       " 'must': 2626,\n",
       " 'call': 616,\n",
       " 'repchriscollins': 3290,\n",
       " 'resign': 3388,\n",
       " 'person': 2906,\n",
       " 'above': 116,\n",
       " 'law': 2314,\n",
       " 'officialcbc': 2752,\n",
       " 'cbc': 665,\n",
       " 'repjeffries': 3320,\n",
       " 'elected': 1327,\n",
       " 'caucus': 662,\n",
       " 'chair': 682,\n",
       " 'clyburn': 779,\n",
       " 'majority': 2440,\n",
       " 'whip': 4425,\n",
       " 'making': 2445,\n",
       " 'keep': 2250,\n",
       " 'energycommerce': 1371,\n",
       " 'fcc': 1533,\n",
       " 'goes': 1734,\n",
       " 'fight': 1555,\n",
       " 'free': 1658,\n",
       " 'open': 2772,\n",
       " 'internet': 2127,\n",
       " 'continues': 917,\n",
       " 'th': 4008,\n",
       " 'ban': 405,\n",
       " 'trans': 4119,\n",
       " 'serving': 3641,\n",
       " 'nation': 2647,\n",
       " 'military': 2540,\n",
       " 'purpose': 3124,\n",
       " 'built': 586,\n",
       " 'humiliate': 1983,\n",
       " 'brave': 547,\n",
       " 'under': 4201,\n",
       " 'republican': 3377,\n",
       " 'control': 927,\n",
       " 'didn': 1175,\n",
       " 'hold': 1925,\n",
       " 'single': 3708,\n",
       " 'hearing': 1871,\n",
       " 'gun': 1801,\n",
       " 'violence': 4319,\n",
       " 'prevention': 3037,\n",
       " 'streak': 3862,\n",
       " 'ends': 1365,\n",
       " 'had': 1808,\n",
       " 'opposition': 2785,\n",
       " 'party': 2851,\n",
       " 'won': 4471,\n",
       " 'down': 1260,\n",
       " 'least': 2334,\n",
       " '10': 4,\n",
       " 'point': 2951,\n",
       " 'tonight': 4085,\n",
       " 'sending': 3612,\n",
       " 'legislation': 2345,\n",
       " 'desk': 1146,\n",
       " 're': 3170,\n",
       " 'dni': 1226,\n",
       " 'dan': 1036,\n",
       " 'coats': 784,\n",
       " 'says': 3533,\n",
       " 'warning': 4367,\n",
       " 'lights': 2369,\n",
       " 'blinking': 504,\n",
       " 'red': 3214,\n",
       " 'russian': 3496,\n",
       " 'cyberattacks': 1027,\n",
       " 'why': 4436,\n",
       " 'housegop': 1962,\n",
       " 'concrete': 852,\n",
       " 'ste': 3822,\n",
       " 'absolutely': 119,\n",
       " 'collusion': 799,\n",
       " 'kimberley': 2268,\n",
       " 'strassel': 3861,\n",
       " 'fab': 1484,\n",
       " 'geraldorivera': 1707,\n",
       " 'what': 4416,\n",
       " 'fairness': 1498,\n",
       " 'good': 1742,\n",
       " 'say': 3531,\n",
       " 'enough': 1379,\n",
       " 'already': 252,\n",
       " 'specialcounsel': 3773,\n",
       " 'collusi': 798,\n",
       " 'ap': 311,\n",
       " 'norc': 2705,\n",
       " 'poll': 2964,\n",
       " 'immigration': 2024,\n",
       " 'among': 274,\n",
       " 'top': 4089,\n",
       " 'concerns': 849,\n",
       " '2019': 41,\n",
       " 'drugs': 1282,\n",
       " 'criminals': 996,\n",
       " 'equipment': 1406,\n",
       " 'general': 1700,\n",
       " 'mattis': 2480,\n",
       " 'help': 1882,\n",
       " 'allies': 245,\n",
       " 'other': 2797,\n",
       " 'countries': 960,\n",
       " 'pay': 2875,\n",
       " 'mi': 2527,\n",
       " 'year': 4506,\n",
       " 'hurricanemaria': 1992,\n",
       " 'devastated': 1162,\n",
       " 'puertorico': 3116,\n",
       " 'usvirginislands': 4282,\n",
       " 'yet': 4511,\n",
       " 'refuse': 3229,\n",
       " 'fdr': 1535,\n",
       " 'dreamed': 1272,\n",
       " 'about': 115,\n",
       " 'deal': 1064,\n",
       " 'back': 393,\n",
       " 'work': 4477,\n",
       " 'think': 4033,\n",
       " 'lbj': 2322,\n",
       " 'he': 1859,\n",
       " 'gave': 1693,\n",
       " 'food': 1614,\n",
       " 'never': 2676,\n",
       " 'firefighters': 1577,\n",
       " 'communities': 828,\n",
       " 'pleasure': 2942,\n",
       " 'repdebdingell': 3300,\n",
       " 'belleville': 454,\n",
       " 'mom': 2575,\n",
       " 'now': 2713,\n",
       " 'facing': 1489,\n",
       " 'daycare': 1054,\n",
       " 'bill': 481,\n",
       " 'she': 3666,\n",
       " 'cannot': 635,\n",
       " 'afford': 188,\n",
       " 'started': 3812,\n",
       " 'working': 4484,\n",
       " 'midnight': 2532,\n",
       " 'ivankatrump': 2173,\n",
       " 'exemplary': 1456,\n",
       " 'service': 3639,\n",
       " 'secretary': 3566,\n",
       " 'wilson': 4449,\n",
       " 'suffering': 3910,\n",
       " 'challenge': 685,\n",
       " 'moral': 2589,\n",
       " 'conscience': 890,\n",
       " 'unlawful': 4229,\n",
       " 'over': 2814,\n",
       " 'exist': 1460,\n",
       " 'constitution': 902,\n",
       " 'world': 4486,\n",
       " 'scientists': 3552,\n",
       " 'agree': 211,\n",
       " 'confront': 872,\n",
       " 'threat': 4047,\n",
       " 'climate': 768,\n",
       " 'truly': 4154,\n",
       " 'safety': 3508,\n",
       " 'security': 3579,\n",
       " 'equality': 1403,\n",
       " 'justice': 2242,\n",
       " 'healthcare': 1868,\n",
       " 'economic': 1308,\n",
       " 'securi': 3576,\n",
       " 'respected': 3396,\n",
       " 'again': 201,\n",
       " 'icymi': 2000,\n",
       " 'tax': 3970,\n",
       " 'cuts': 1025,\n",
       " 'provide': 3106,\n",
       " 'limited': 2373,\n",
       " 'boost': 527,\n",
       " 'wages': 4349,\n",
       " 'wsj': 4501,\n",
       " 'buybacks': 601,\n",
       " 'poised': 2953,\n",
       " 'ecl': 1306,\n",
       " 'stand': 3803,\n",
       " 'right': 3445,\n",
       " 'believesurvivors': 453,\n",
       " 'fbi': 1531,\n",
       " 'allowed': 247,\n",
       " 'investigate': 2143,\n",
       " 'credible': 990,\n",
       " 'chairman': 683,\n",
       " 'johndingell': 2210,\n",
       " 'hand': 1815,\n",
       " 'crafting': 981,\n",
       " 'major': 2439,\n",
       " 'legislative': 2346,\n",
       " 'accomplishments': 133,\n",
       " 'past': 2859,\n",
       " 'bu': 580,\n",
       " 'kelly': 2257,\n",
       " 'done': 1246,\n",
       " 'an': 275,\n",
       " 'outstanding': 2810,\n",
       " 'job': 2205,\n",
       " 'representing': 3359,\n",
       " 'doubt': 1255,\n",
       " 'her': 1889,\n",
       " 'leadership': 2326,\n",
       " 'danielmorain': 1041,\n",
       " 'nancy': 2641,\n",
       " 'pelosi': 2886,\n",
       " 'gcas2018': 1697,\n",
       " 'happening': 1826,\n",
       " 'am': 257,\n",
       " 'ever': 1430,\n",
       " 'hopeful': 1945,\n",
       " 'briefing': 561,\n",
       " 'team': 3978,\n",
       " 'north': 2707,\n",
       " 'korea': 2284,\n",
       " 'made': 2435,\n",
       " 'next': 2685,\n",
       " 'summit': 3913,\n",
       " 'wrote': 4500,\n",
       " 'recommending': 3206,\n",
       " 'state': 3815,\n",
       " 'union': 4218,\n",
       " 'until': 4239,\n",
       " 'white': 4430,\n",
       " 'honoring': 1942,\n",
       " 'responsibility': 3401,\n",
       " 'ame': 264,\n",
       " 'longest': 2401,\n",
       " 'fire': 1574,\n",
       " 'chief': 719,\n",
       " 'city': 744,\n",
       " 'hayes': 1856,\n",
       " 'led': 2337,\n",
       " 'sffd': 3652,\n",
       " 'become': 431,\n",
       " 'diversifi': 1220,\n",
       " 'congratulations': 877,\n",
       " 'football': 1616,\n",
       " 'clemson': 763,\n",
       " 'tigers': 4068,\n",
       " 'incredible': 2058,\n",
       " 'night': 2690,\n",
       " 'against': 202,\n",
       " 'power': 2992,\n",
       " 'tomfitton': 4083,\n",
       " 'dem': 1112,\n",
       " 'likely': 2371,\n",
       " 'face': 1485,\n",
       " 'doj': 1237,\n",
       " 'perjury': 2900,\n",
       " 'probe': 3058,\n",
       " 'foxnews': 1647,\n",
       " 'trumpshutdown': 4161,\n",
       " 'pushed': 3127,\n",
       " 'hundreds': 1986,\n",
       " 'thousands': 4044,\n",
       " 'breaking': 552,\n",
       " 'pushing': 3128,\n",
       " 'looks': 2404,\n",
       " 'like': 2370,\n",
       " 'wonderful': 4474,\n",
       " 'four': 1645,\n",
       " 'strong': 3877,\n",
       " 'women': 4469,\n",
       " 'leaders': 2325,\n",
       " 'forefront': 1624,\n",
       " 'such': 3906,\n",
       " 'promised': 3075,\n",
       " 'exactly': 1441,\n",
       " 'doing': 1236,\n",
       " 'congre': 878,\n",
       " 'rank': 3160,\n",
       " 'file': 1559,\n",
       " 'disgusted': 1209,\n",
       " 'learning': 2333,\n",
       " 'lyin': 2431,\n",
       " 'james': 2180,\n",
       " 'comey': 808,\n",
       " 'spent': 3779,\n",
       " 'vietnam': 4312,\n",
       " 'than': 4010,\n",
       " 'da': 1030,\n",
       " 'nang': 2643,\n",
       " 'dick': 1173,\n",
       " 'blumenthal': 512,\n",
       " 'third': 4035,\n",
       " 'rate': 3164,\n",
       " 'connecticut': 888,\n",
       " 'designed': 1145,\n",
       " 'deeply': 1092,\n",
       " 'concerning': 848,\n",
       " 'dod': 1231,\n",
       " 'officials': 2754,\n",
       " 'appear': 313,\n",
       " 'ha': 1807,\n",
       " 'gas': 1691,\n",
       " 'low': 2420,\n",
       " 'expected': 1467,\n",
       " 'janschakowsky': 2182,\n",
       " 'agonize': 210,\n",
       " 'organize': 2794,\n",
       " 'nancypelosi': 2642,\n",
       " 'pro': 3056,\n",
       " 'woman': 4468,\n",
       " 'colle': 791,\n",
       " 'so': 3730,\n",
       " 'nice': 2687,\n",
       " 'well': 4407,\n",
       " 'speech': 3774,\n",
       " 'received': 3194,\n",
       " 'otto': 2799,\n",
       " 'mistreatment': 2564,\n",
       " 'warmbier': 4365,\n",
       " 'died': 1177,\n",
       " 'vain': 4285,\n",
       " 'famil': 1511,\n",
       " 'russia': 3495,\n",
       " 'dossier': 1252,\n",
       " 'reporter': 3348,\n",
       " 'doubts': 1256,\n",
       " 'dopey': 1250,\n",
       " 'christopher': 735,\n",
       " 'steele': 3825,\n",
       " 'claims': 750,\n",
       " 'when': 4419,\n",
       " 'get': 1710,\n",
       " 'details': 1155,\n",
       " 'admission': 172,\n",
       " 'paying': 2881,\n",
       " 'dollars': 1240,\n",
       " 'hush': 1998,\n",
       " 'direction': 1187,\n",
       " 'candidate': 633,\n",
       " 'almost': 248,\n",
       " 'usd23': 4263,\n",
       " 'billion': 482,\n",
       " 'regardless': 3234,\n",
       " 'speak': 3766,\n",
       " 'send': 3610,\n",
       " 'greetings': 1778,\n",
       " 'those': 4039,\n",
       " 'celebrating': 669,\n",
       " 'lunar': 2428,\n",
       " 'across': 143,\n",
       " 'united': 4222,\n",
       " 'states': 3819,\n",
       " 'enthusiasm': 1390,\n",
       " 'appoint': 318,\n",
       " 'usrepkcastor': 4278,\n",
       " 'select': 3591,\n",
       " 'committee': 822,\n",
       " 'cr': 978,\n",
       " 'thanks': 4013,\n",
       " 'randpaul': 3159,\n",
       " 'donaldnorcross': 1245,\n",
       " 'infrastructure': 2082,\n",
       " 'needs': 2665,\n",
       " 'update': 4247,\n",
       " 'hard': 1833,\n",
       " 'men': 2518,\n",
       " 'nationwide': 2649,\n",
       " 'walk': 4353,\n",
       " 'office': 2749,\n",
       " 'each': 1291,\n",
       " 'morning': 2593,\n",
       " 'give': 1720,\n",
       " 'dedication': 1088,\n",
       " 'generations': 1702,\n",
       " 'criminal': 995,\n",
       " 'reform': 3226,\n",
       " 'known': 2282,\n",
       " 'firststepact': 1583,\n",
       " 'weekly': 4399,\n",
       " 'press': 3029,\n",
       " 'conference': 863,\n",
       " '45': 75,\n",
       " 'tune': 4172,\n",
       " 'witch': 4462,\n",
       " 'hunt': 1989,\n",
       " 'end': 1358,\n",
       " 'realize': 3182,\n",
       " 'crooked': 1000,\n",
       " 'hillary': 1906,\n",
       " 'clinton': 771,\n",
       " 'nadler': 2634,\n",
       " 'expect': 1466,\n",
       " 'presidents': 3027,\n",
       " 'own': 2829,\n",
       " 'failures': 1496,\n",
       " 'watch': 4376,\n",
       " 'prepare': 3012,\n",
       " 'legisla': 2343,\n",
       " 'repcheri': 3288,\n",
       " 'hey': 1896,\n",
       " 'taxpayers': 3973,\n",
       " 'much': 2615,\n",
       " 'familyseparation': 1515,\n",
       " 'putting': 3131,\n",
       " 'kids': 2262,\n",
       " 'cag': 609,\n",
       " 'drleanawen': 1278,\n",
       " 'becoming': 433,\n",
       " 'ppfa': 2996,\n",
       " 'vision': 4323,\n",
       " 'critical': 998,\n",
       " 'jens': 2192,\n",
       " 'stoltenberg': 3847,\n",
       " 'nato': 2651,\n",
       " 'stated': 3816,\n",
       " 'able': 112,\n",
       " 'raise': 3149,\n",
       " 'far': 1520,\n",
       " 'folk': 1610,\n",
       " 'singer': 3707,\n",
       " 'buddy': 581,\n",
       " 'mondlock': 2579,\n",
       " 'got': 1751,\n",
       " 'hepatitis': 1888,\n",
       " 'blood': 509,\n",
       " 'transfusion': 4123,\n",
       " 'car': 643,\n",
       " 'accident': 130,\n",
       " '1981': 28,\n",
       " 'decades': 1073,\n",
       " 'bei': 447,\n",
       " 'asked': 351,\n",
       " 'china': 722,\n",
       " 'immediately': 2019,\n",
       " 'remove': 3266,\n",
       " 'tariffs': 3965,\n",
       " 'agricultural': 216,\n",
       " 'products': 3067,\n",
       " 'including': 2051,\n",
       " 'beef': 434,\n",
       " 'pork': 2971,\n",
       " 'etc': 1418,\n",
       " 'base': 417,\n",
       " 'hardworking': 1836,\n",
       " 'unionized': 4219,\n",
       " 'public': 3113,\n",
       " 'servants': 3634,\n",
       " 'afgenational': 190,\n",
       " 'attacks': 372,\n",
       " 'deserve': 1141,\n",
       " 'answers': 295,\n",
       " 'scandal': 3539,\n",
       " 'means': 2499,\n",
       " 'mueller': 2616,\n",
       " 'investigation': 2147,\n",
       " 'lawyers': 2320,\n",
       " 'represented': 3358,\n",
       " 'unfortunately': 4213,\n",
       " 'clients': 766,\n",
       " 'also': 253,\n",
       " 'disba': 1192,\n",
       " 'opportunity': 2781,\n",
       " 'sit': 3710,\n",
       " 'chriscuomo': 732,\n",
       " 'afternoon': 199,\n",
       " 'firing': 1579,\n",
       " 'ag': 200,\n",
       " 'sessions': 3643,\n",
       " 'priorities': 3050,\n",
       " 'case': 656,\n",
       " 'crime': 993,\n",
       " 'kno': 2278,\n",
       " 'called': 617,\n",
       " 'worker': 4479,\n",
       " 'steve': 3833,\n",
       " 'moore': 2587,\n",
       " 'co': 781,\n",
       " 'author': 383,\n",
       " 'trumponomics': 4159,\n",
       " 'indeed': 2059,\n",
       " 'ye': 4505,\n",
       " 'hoax': 1923,\n",
       " 'insurance': 2109,\n",
       " 'before': 437,\n",
       " 'even': 1426,\n",
       " 'bad': 399,\n",
       " 'hearts': 1875,\n",
       " 'heavy': 1877,\n",
       " 'impacted': 2027,\n",
       " 'wildfires': 4443,\n",
       " 'california': 613,\n",
       " 'humbled': 1982,\n",
       " 'day': 1053,\n",
       " 'moment': 2576,\n",
       " 'listen': 2384,\n",
       " 'whitehouse': 4431,\n",
       " 'every': 1431,\n",
       " 'community': 829,\n",
       " 'peace': 2885,\n",
       " 'moments': 2577,\n",
       " 'stood': 3849,\n",
       " 'us': 4255,\n",
       " 'diagnosis': 1170,\n",
       " 'phone': 2917,\n",
       " 'away': 390,\n",
       " 'needing': 2664,\n",
       " 'condition': 859,\n",
       " 'protections': 3095,\n",
       " 'spark': 3765,\n",
       " 'divinity': 1223,\n",
       " 'ensure': 1386,\n",
       " 'children': 721,\n",
       " 'trea': 4130,\n",
       " 'sebgorka': 3562,\n",
       " 'protected': 3092,\n",
       " 'grt': 1791,\n",
       " 'enforcmt': 1373,\n",
       " 'importantly': 2035,\n",
       " 'god': 1732,\n",
       " 'went': 4409,\n",
       " 'davos': 1052,\n",
       " 'should': 3679,\n",
       " 'decided': 1077,\n",
       " 'gopchairwoman': 1748,\n",
       " 'sure': 3924,\n",
       " 'coast': 783,\n",
       " 'guard': 1795,\n",
       " 'schumershutdown': 3551,\n",
       " 'mea': 2495,\n",
       " 'september11th': 3630,\n",
       " 'related': 3249,\n",
       " 'illnesses': 2013,\n",
       " 'meet': 2508,\n",
       " 'commitment': 818,\n",
       " 'playing': 2938,\n",
       " 'politics': 2963,\n",
       " 'foxandfriends': 1646,\n",
       " 'seven': 3648,\n",
       " 'ago': 209,\n",
       " 'took': 4087,\n",
       " 'firm': 1580,\n",
       " 'bigotry': 480,\n",
       " 'discriminatory': 1200,\n",
       " 'ask': 350,\n",
       " 'tell': 3983,\n",
       " 'patrol': 2867,\n",
       " 'local': 2394,\n",
       " 'enforcement': 1372,\n",
       " 'doin': 1235,\n",
       " 'busy': 598,\n",
       " 'reporters': 3349,\n",
       " 'clearest': 761,\n",
       " 'sign': 3695,\n",
       " 'faketrumpemergency': 1503,\n",
       " 'legitimate': 2348,\n",
       " 'himself': 1909,\n",
       " 'let': 2354,\n",
       " 'gop': 1746,\n",
       " 'cruel': 1009,\n",
       " 'lawsuit': 2318,\n",
       " 'affordable': 189,\n",
       " 'health': 1867,\n",
       " 'remember': 3262,\n",
       " 'de': 1061,\n",
       " 'repcolinallred': 3293,\n",
       " 'focus': 1608,\n",
       " 'helping': 1884,\n",
       " 'home': 1932,\n",
       " 'better': 467,\n",
       " 'jobs': 2206,\n",
       " 'lower': 2421,\n",
       " 'costs': 951,\n",
       " 'recognized': 3204,\n",
       " 'greatest': 1774,\n",
       " 'political': 2959,\n",
       " 'history': 1918,\n",
       " 'level': 2358,\n",
       " 'staffer': 3797,\n",
       " 'hardly': 1835,\n",
       " 'knew': 2276,\n",
       " 'named': 2640,\n",
       " 'cliff': 767,\n",
       " 'sims': 3705,\n",
       " 'another': 292,\n",
       " 'boring': 532,\n",
       " 'book': 523,\n",
       " 'stories': 3855,\n",
       " 'cbs': 667,\n",
       " 'reports': 3351,\n",
       " 'roger': 3465,\n",
       " 'stone': 3848,\n",
       " 'indictment': 2063,\n",
       " 'data': 1045,\n",
       " 'released': 3252,\n",
       " 'damage': 1034,\n",
       " 'clint': 770,\n",
       " 'guided': 1798,\n",
       " ...}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'vocabulary_' is a dictionary that converts each word to its index in the sparse matrix\n",
    "print('Number of features (unique words):', len(vect.vocabulary_))\n",
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomial Naive Bayes classifier (text features only with non-negative values)\n",
    "- Note: MultinomialNB does not accept negative values (i.e., sentiment feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy score: 0.893\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a Naive Bayes classifier for multinomial models and fit Naive Bayes classifier according to X, y\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_dtm, y_train)\n",
    "\n",
    "# Predict the class using the Multinomial Naive Bayes classifier\n",
    "y_pred_class = nb.predict(X_test_dtm)\n",
    "\n",
    "# Testing accuracy classification score\n",
    "print('Testing accuracy score:', round(metrics.accuracy_score(y_test, y_pred_class), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian Naive Bayes classifier (text features and additional features which may include negative values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy score: 0.865\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a Gaussian Naive Bayes classifier and fit Gaussian Naive Bayes classifier according to X, y\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train_dtm_extra.toarray(), y_train)\n",
    "    \n",
    "# Predict the class using the Gaussian Naive Bayes classifier\n",
    "y_pred_class = gnb.predict(X_test_dtm_extra.toarray())\n",
    "    \n",
    "# Testing accuracy classification score\n",
    "print('Testing accuracy score:', round(metrics.accuracy_score(y_test, y_pred_class), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression classifier (text features and additional features which may include negative values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy score: 0.893\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a Logistic Regression classifier and fit logistic model\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_dtm_extra, y_train)  \n",
    "\n",
    "# Predict the class using the logistic model\n",
    "y_pred_class = logreg.predict(X_test_dtm_extra)\n",
    "\n",
    "# Testing accuracy classification score\n",
    "print('Testing accuracy score:', round(metrics.accuracy_score(y_test, y_pred_class), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Naive Bayes classifier for multinomial models with text feature columns only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Define a function that accepts a vectorizer and calculates the accuracy\n",
    "def tokenize_test_mnb(vect):\n",
    "    print()\n",
    "    # Learn the vocabulary dictionary and return term-document matrix\n",
    "    # -> This is equivalent to fit followed by transform, but more efficiently implemented\n",
    "    X_train_dtm = vect.fit_transform(X_train.clean_text) \n",
    "    \n",
    "    # Transform documents to document-term matrix\n",
    "    # -> Extract token counts out of raw text documents using the vocabulary fitted with fit or the one provided to the constructor\n",
    "    X_test_dtm = vect.transform(X_test.clean_text)\n",
    "    \n",
    "    print('Multinomial Naive Bayes classifier (text features only with non-negative values)')\n",
    "    \n",
    "    # Instantiate a Naive Bayes classifier for multinomial models and fit Naive Bayes classifier according to X, y\n",
    "    mnb = MultinomialNB()\n",
    "    mnb.fit(X_train_dtm, y_train)\n",
    "    \n",
    "    # Return the number of columns (terms (aka \"tokens\" or \"features\"; individual words in this situation)) of the DataFrame\n",
    "    print('Features: {}'.format(X_train_dtm.shape[1]))\n",
    "    \n",
    "    # Predict the class using the Naive Bayes classifier\n",
    "    y_pred_class = mnb.predict(X_test_dtm)\n",
    "    \n",
    "    # Testing accuracy classification score\n",
    "    print('Testing accuracy score:', round(metrics.accuracy_score(y_test, y_pred_class), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Gaussian Naive Bayes classifier with all feature columns (may include negative values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Define a function that accepts a vectorizer and calculates the accuracy\n",
    "def tokenize_test_gnb(vect):\n",
    "    print()\n",
    "    # Learn the vocabulary dictionary and return term-document matrix\n",
    "    # -> This is equivalent to fit followed by transform, but more efficiently implemented\n",
    "    X_train_dtm = vect.fit_transform(X_train.clean_text) \n",
    "    \n",
    "    # Transform documents to document-term matrix\n",
    "    # -> Extract token counts out of raw text documents using the vocabulary fitted with fit or the one provided to the constructor\n",
    "    X_test_dtm = vect.transform(X_test.clean_text)\n",
    "    \n",
    "    # Training set -> Cast other feature columns to float and convert to a sparse matrix\n",
    "    # Compressed Sparse Row matrix\n",
    "    extra = sp.sparse.csr_matrix(X_train.drop('clean_text', axis=1).astype(float))\n",
    "\n",
    "    # Combine sparse matrices\n",
    "    # -> Stack sparse matrices horizontally (column wise)\n",
    "    X_train_dtm_extra = sp.sparse.hstack((X_train_dtm, extra))\n",
    "\n",
    "    # Testing set -> Cast other feature columns to float and convert to a sparse matrix\n",
    "    # Compressed Sparse Row matrix\n",
    "    extra = sp.sparse.csr_matrix(X_test.drop('clean_text', axis=1).astype(float))\n",
    "    \n",
    "    # Combine sparse matrices\n",
    "    # -> Stack sparse matrices horizontally (column wise)\n",
    "    X_test_dtm_extra = sp.sparse.hstack((X_test_dtm, extra))\n",
    "    \n",
    "    print('Gaussian Naive Bayes classifier (text features and additional features which may include negative values)')\n",
    "    \n",
    "    # Instantiate a Gaussian Naive Bayes classifier and fit Gaussian Naive Bayes classifier according to X, y\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(X_train_dtm_extra.toarray(), y_train)\n",
    "    \n",
    "    # Return the number of columns (terms (aka \"tokens\" or \"features\"; individual words in this situation)) of the DataFrame\n",
    "    print('Features: {}'.format(X_train_dtm_extra.shape[1]))\n",
    "    \n",
    "    # Predict the class using the Gaussian Naive Bayes classifier\n",
    "    y_pred_class = gnb.predict(X_test_dtm_extra.toarray())\n",
    "    \n",
    "    # Testing accuracy classification score\n",
    "    print('Testing accuracy score:', round(metrics.accuracy_score(y_test, y_pred_class), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Logistic Regression classifier with all feature columns (may include negative values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Define a function that accepts a vectorizer and calculates the accuracy\n",
    "def tokenize_test_logreg(vect):\n",
    "    print()\n",
    "    # Learn the vocabulary dictionary and return term-document matrix\n",
    "    # -> This is equivalent to fit followed by transform, but more efficiently implemented\n",
    "    X_train_dtm = vect.fit_transform(X_train.clean_text) \n",
    "    \n",
    "    # Transform documents to document-term matrix\n",
    "    # -> Extract token counts out of raw text documents using the vocabulary fitted with fit or the one provided to the constructor\n",
    "    X_test_dtm = vect.transform(X_test.clean_text)\n",
    "    \n",
    "    # Training set -> Cast other feature columns to float and convert to a sparse matrix\n",
    "    # Compressed Sparse Row matrix\n",
    "    extra = sp.sparse.csr_matrix(X_train.drop('clean_text', axis=1).astype(float))\n",
    "\n",
    "    # Combine sparse matrices\n",
    "    # -> Stack sparse matrices horizontally (column wise)\n",
    "    X_train_dtm_extra = sp.sparse.hstack((X_train_dtm, extra))\n",
    "\n",
    "    # Testing set -> Cast other feature columns to float and convert to a sparse matrix\n",
    "    # Compressed Sparse Row matrix\n",
    "    extra = sp.sparse.csr_matrix(X_test.drop('clean_text', axis=1).astype(float))\n",
    "    \n",
    "    # Combine sparse matrices\n",
    "    # -> Stack sparse matrices horizontally (column wise)\n",
    "    X_test_dtm_extra = sp.sparse.hstack((X_test_dtm, extra))\n",
    "    \n",
    "    print('Logistic Regression classifier (text features and additional features which may include negative values)')\n",
    "    \n",
    "    # Instantiate a Logistic Regression classifier and fit logistic model\n",
    "    logreg = LogisticRegression()\n",
    "    logreg.fit(X_train_dtm_extra, y_train)  \n",
    "    \n",
    "    # Return the number of columns (terms (aka \"tokens\" or \"features\"; individual words in this situation)) of the DataFrame\n",
    "    print('Features: {}'.format(X_train_dtm_extra.shape[1]))\n",
    "    \n",
    "    # Predict the class using the logistic model\n",
    "    y_pred_class = logreg.predict(X_test_dtm_extra)\n",
    "    \n",
    "    # Testing accuracy classification score\n",
    "    print('Testing accuracy score:', round(metrics.accuracy_score(y_test, y_pred_class), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Features Using CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Including 1-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4m1-grams only:\u001b[0m\n",
      "\n",
      "Multinomial Naive Bayes classifier (text features only with non-negative values)\n",
      "Features: 4541\n",
      "Testing accuracy score: 0.893\n",
      "\n",
      "Gaussian Naive Bayes classifier (text features and additional features which may include negative values)\n",
      "Features: 4542\n",
      "Testing accuracy score: 0.865\n",
      "\n",
      "Logistic Regression classifier (text features and additional features which may include negative values)\n",
      "Features: 4542\n",
      "Testing accuracy score: 0.893\n",
      "\u001b[4m\n",
      "1-grams only, remove stop words:\u001b[0m\n",
      "\n",
      "Multinomial Naive Bayes classifier (text features only with non-negative values)\n",
      "Features: 4306\n",
      "Testing accuracy score: 0.895\n",
      "\n",
      "Gaussian Naive Bayes classifier (text features and additional features which may include negative values)\n",
      "Features: 4307\n",
      "Testing accuracy score: 0.852\n",
      "\n",
      "Logistic Regression classifier (text features and additional features which may include negative values)\n",
      "Features: 4307\n",
      "Testing accuracy score: 0.895\n",
      "\u001b[4m\n",
      "1-grams only, remove stop words, only include terms that appear at least two times:\u001b[0m\n",
      "\n",
      "Multinomial Naive Bayes classifier (text features only with non-negative values)\n",
      "Features: 1833\n",
      "Testing accuracy score: 0.87\n",
      "\n",
      "Gaussian Naive Bayes classifier (text features and additional features which may include negative values)\n",
      "Features: 1834\n",
      "Testing accuracy score: 0.827\n",
      "\n",
      "Logistic Regression classifier (text features and additional features which may include negative values)\n",
      "Features: 1834\n",
      "Testing accuracy score: 0.892\n",
      "\u001b[4m\n",
      "1-grams only, remove stop words, up to 5000 features:\u001b[0m\n",
      "\n",
      "Multinomial Naive Bayes classifier (text features only with non-negative values)\n",
      "Features: 4306\n",
      "Testing accuracy score: 0.895\n",
      "\n",
      "Gaussian Naive Bayes classifier (text features and additional features which may include negative values)\n",
      "Features: 4307\n",
      "Testing accuracy score: 0.852\n",
      "\n",
      "Logistic Regression classifier (text features and additional features which may include negative values)\n",
      "Features: 4307\n",
      "Testing accuracy score: 0.895\n"
     ]
    }
   ],
   "source": [
    "# Instantiate CountVectorizer to convert a collection of text documents to a matrix of token counts\n",
    "# -> This implementation produces a sparse representation of the counts using scipy.sparse.csr_matrix\n",
    "# Note: lowercase: convert all characters to lowercase before tokenizing; default is True\n",
    "#       stop_words: if 'english', a built-in stop word list for English is used; default is None\n",
    "#       ngram_range: tuple (min_n, max_n); the lower and upper boundary of the range of n-values for \n",
    "#                    different n-grams to be extracted; all values of n such that min_n <= n <= max_n will be used\n",
    "#       min_df: when building the vocabulary ignore terms that have a 'document frequency' strictly lower than the \n",
    "#               given threshold; this value is also called cut-off in the literature\n",
    "#       max_features: build a vocabulary that only considers the top max_features ordered by term frequency across the corpus\n",
    "print('\\033[4m' + '1-grams only:' +  '\\033[0m')\n",
    "vect = CountVectorizer(lowercase=True, ngram_range=(1, 1))\n",
    "tokenize_test_mnb(vect)\n",
    "tokenize_test_gnb(vect)\n",
    "tokenize_test_logreg(vect)\n",
    "\n",
    "print('\\033[4m' + '\\n1-grams only, remove stop words:' +  '\\033[0m')\n",
    "vect = CountVectorizer(lowercase=True, stop_words='english', ngram_range=(1, 1))\n",
    "tokenize_test_mnb(vect)\n",
    "tokenize_test_gnb(vect)\n",
    "tokenize_test_logreg(vect)\n",
    "\n",
    "print('\\033[4m' + '\\n1-grams only, remove stop words, only include terms that appear at least two times:' +  '\\033[0m')\n",
    "vect = CountVectorizer(lowercase=True, stop_words='english', ngram_range=(1, 1), min_df=2)\n",
    "tokenize_test_mnb(vect)\n",
    "tokenize_test_gnb(vect)\n",
    "tokenize_test_logreg(vect)\n",
    "\n",
    "print('\\033[4m' + '\\n1-grams only, remove stop words, up to 5000 features:' +  '\\033[0m')\n",
    "vect = CountVectorizer(lowercase=True, stop_words='english', ngram_range=(1, 1), max_features=5000)\n",
    "tokenize_test_mnb(vect)\n",
    "tokenize_test_gnb(vect)\n",
    "tokenize_test_logreg(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the effective stop words list\n",
    "#print('Number of stop words:', len(vect.get_stop_words()))\n",
    "#print(vect.get_stop_words())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Including 1-Grams and 2-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4m1-grams and 2-grams:\u001b[0m\n",
      "\n",
      "Multinomial Naive Bayes classifier (text features only with non-negative values)\n",
      "Features: 21047\n",
      "Testing accuracy score: 0.905\n",
      "\n",
      "Gaussian Naive Bayes classifier (text features and additional features which may include negative values)\n",
      "Features: 21048\n",
      "Testing accuracy score: 0.897\n",
      "\n",
      "Logistic Regression classifier (text features and additional features which may include negative values)\n",
      "Features: 21048\n",
      "Testing accuracy score: 0.878\n",
      "\u001b[4m\n",
      "1-grams and 2-grams, remove stop words:\u001b[0m\n",
      "\n",
      "Multinomial Naive Bayes classifier (text features only with non-negative values)\n",
      "Features: 15755\n",
      "Testing accuracy score: 0.907\n",
      "\n",
      "Gaussian Naive Bayes classifier (text features and additional features which may include negative values)\n",
      "Features: 15756\n",
      "Testing accuracy score: 0.88\n",
      "\n",
      "Logistic Regression classifier (text features and additional features which may include negative values)\n",
      "Features: 15756\n",
      "Testing accuracy score: 0.89\n",
      "\u001b[4m\n",
      "1-grams and 2-grams, remove stop words, only include terms that appear at least two times:\u001b[0m\n",
      "\n",
      "Multinomial Naive Bayes classifier (text features only with non-negative values)\n",
      "Features: 2881\n",
      "Testing accuracy score: 0.878\n",
      "\n",
      "Gaussian Naive Bayes classifier (text features and additional features which may include negative values)\n",
      "Features: 2882\n",
      "Testing accuracy score: 0.848\n",
      "\n",
      "Logistic Regression classifier (text features and additional features which may include negative values)\n",
      "Features: 2882\n",
      "Testing accuracy score: 0.893\n",
      "\u001b[4m\n",
      "1-grams and 2-grams, remove stop words, up to 2760 features:\u001b[0m\n",
      "\n",
      "Multinomial Naive Bayes classifier (text features only with non-negative values)\n",
      "Features: 2760\n",
      "Testing accuracy score: 0.88\n",
      "\n",
      "Gaussian Naive Bayes classifier (text features and additional features which may include negative values)\n",
      "Features: 2761\n",
      "Testing accuracy score: 0.847\n",
      "\n",
      "Logistic Regression classifier (text features and additional features which may include negative values)\n",
      "Features: 2761\n",
      "Testing accuracy score: 0.895\n"
     ]
    }
   ],
   "source": [
    "# Instantiate CountVectorizer to convert a collection of text documents to a matrix of token counts\n",
    "# -> This implementation produces a sparse representation of the counts using scipy.sparse.csr_matrix\n",
    "# Note: lowercase: convert all characters to lowercase before tokenizing; default is True\n",
    "#       stop_words: if 'english', a built-in stop word list for English is used; default is None\n",
    "#       ngram_range: tuple (min_n, max_n); the lower and upper boundary of the range of n-values for \n",
    "#                    different n-grams to be extracted; all values of n such that min_n <= n <= max_n will be used\n",
    "#       min_df: when building the vocabulary ignore terms that have a 'document frequency' strictly lower than the \n",
    "#               given threshold; this value is also called cut-off in the literature\n",
    "#       max_features: build a vocabulary that only considers the top max_features ordered by term frequency across the corpus\n",
    "print('\\033[4m' + '1-grams and 2-grams:' +  '\\033[0m')\n",
    "vect = CountVectorizer(lowercase=True, ngram_range=(1, 2))\n",
    "tokenize_test_mnb(vect)\n",
    "tokenize_test_gnb(vect)\n",
    "tokenize_test_logreg(vect)\n",
    "\n",
    "print('\\033[4m' + '\\n1-grams and 2-grams, remove stop words:' +  '\\033[0m')\n",
    "vect = CountVectorizer(lowercase=True, stop_words='english', ngram_range=(1, 2))\n",
    "tokenize_test_mnb(vect)\n",
    "tokenize_test_gnb(vect)\n",
    "tokenize_test_logreg(vect)\n",
    "\n",
    "print('\\033[4m' + '\\n1-grams and 2-grams, remove stop words, only include terms that appear at least two times:' +  '\\033[0m')\n",
    "vect = CountVectorizer(lowercase=True, stop_words='english', ngram_range=(1, 2), min_df=2)\n",
    "tokenize_test_mnb(vect)\n",
    "tokenize_test_gnb(vect)\n",
    "tokenize_test_logreg(vect)\n",
    "\n",
    "print('\\033[4m' + '\\n1-grams and 2-grams, remove stop words, up to 2760 features:' +  '\\033[0m')\n",
    "vect = CountVectorizer(lowercase=True, stop_words='english', ngram_range=(1, 2), max_features=2760)\n",
    "tokenize_test_mnb(vect)\n",
    "tokenize_test_gnb(vect)\n",
    "tokenize_test_logreg(vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Features Using TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Including 1-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4m1-grams only:\u001b[0m\n",
      "\n",
      "Multinomial Naive Bayes classifier (text features only with non-negative values)\n",
      "Features: 4541\n",
      "Testing accuracy score: 0.91\n",
      "\n",
      "Gaussian Naive Bayes classifier (text features and additional features which may include negative values)\n",
      "Features: 4542\n",
      "Testing accuracy score: 0.845\n",
      "\n",
      "Logistic Regression classifier (text features and additional features which may include negative values)\n",
      "Features: 4542\n",
      "Testing accuracy score: 0.885\n",
      "\u001b[4m\n",
      "1-grams only, remove stop words:\u001b[0m\n",
      "\n",
      "Multinomial Naive Bayes classifier (text features only with non-negative values)\n",
      "Features: 4306\n",
      "Testing accuracy score: 0.907\n",
      "\n",
      "Gaussian Naive Bayes classifier (text features and additional features which may include negative values)\n",
      "Features: 4307\n",
      "Testing accuracy score: 0.84\n",
      "\n",
      "Logistic Regression classifier (text features and additional features which may include negative values)\n",
      "Features: 4307\n",
      "Testing accuracy score: 0.908\n",
      "\u001b[4m\n",
      "1-grams only, remove stop words, only include terms that appear at least two times:\u001b[0m\n",
      "\n",
      "Multinomial Naive Bayes classifier (text features only with non-negative values)\n",
      "Features: 1833\n",
      "Testing accuracy score: 0.898\n",
      "\n",
      "Gaussian Naive Bayes classifier (text features and additional features which may include negative values)\n",
      "Features: 1834\n",
      "Testing accuracy score: 0.832\n",
      "\n",
      "Logistic Regression classifier (text features and additional features which may include negative values)\n",
      "Features: 1834\n",
      "Testing accuracy score: 0.902\n",
      "\u001b[4m\n",
      "1-grams only, remove stop words, up to 2700 features:\u001b[0m\n",
      "\n",
      "Multinomial Naive Bayes classifier (text features only with non-negative values)\n",
      "Features: 2700\n",
      "Testing accuracy score: 0.897\n",
      "\n",
      "Gaussian Naive Bayes classifier (text features and additional features which may include negative values)\n",
      "Features: 2701\n",
      "Testing accuracy score: 0.835\n",
      "\n",
      "Logistic Regression classifier (text features and additional features which may include negative values)\n",
      "Features: 2701\n",
      "Testing accuracy score: 0.908\n"
     ]
    }
   ],
   "source": [
    "# Instantiate TfidfVectorizer to convert a collection of raw documents to a matrix of TF-IDF features\n",
    "# -> Equivalent to CountVectorizer followed by TfidfTransformer\n",
    "# Note: lowercase: convert all characters to lowercase before tokenizing; default is True\n",
    "#       stop_words: if 'english', a built-in stop word list for English is used; default is None\n",
    "#       ngram_range: tuple (min_n, max_n); the lower and upper boundary of the range of n-values for \n",
    "#                    different n-grams to be extracted; all values of n such that min_n <= n <= max_n will be used\n",
    "#       min_df: when building the vocabulary ignore terms that have a 'document frequency' strictly lower than the \n",
    "#               given threshold; this value is also called cut-off in the literature\n",
    "#       max_features: build a vocabulary that only considers the top max_features ordered by term frequency across the corpus\n",
    "print('\\033[4m' + '1-grams only:' +  '\\033[0m')\n",
    "vect = TfidfVectorizer(lowercase=True, ngram_range=(1, 1))\n",
    "tokenize_test_mnb(vect)\n",
    "tokenize_test_gnb(vect)\n",
    "tokenize_test_logreg(vect)\n",
    "\n",
    "print('\\033[4m' + '\\n1-grams only, remove stop words:' +  '\\033[0m')\n",
    "vect = TfidfVectorizer(lowercase=True, stop_words='english', ngram_range=(1, 1))\n",
    "tokenize_test_mnb(vect)\n",
    "tokenize_test_gnb(vect)\n",
    "tokenize_test_logreg(vect)\n",
    "\n",
    "print('\\033[4m' + '\\n1-grams only, remove stop words, only include terms that appear at least two times:' +  '\\033[0m')\n",
    "vect = TfidfVectorizer(lowercase=True, stop_words='english', ngram_range=(1, 1), min_df=2)\n",
    "tokenize_test_mnb(vect)\n",
    "tokenize_test_gnb(vect)\n",
    "tokenize_test_logreg(vect)\n",
    "\n",
    "print('\\033[4m' + '\\n1-grams only, remove stop words, up to 2700 features:' +  '\\033[0m')\n",
    "vect = TfidfVectorizer(lowercase=True, stop_words='english', ngram_range=(1, 1), max_features=2700)\n",
    "tokenize_test_mnb(vect)\n",
    "tokenize_test_gnb(vect)\n",
    "tokenize_test_logreg(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the effective stop words list\n",
    "#print('Number of stop words:', len(vect.get_stop_words()))\n",
    "#print(vect.get_stop_words())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Including 1-Grams and 2-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4m1-grams and 2-grams:\u001b[0m\n",
      "\n",
      "Multinomial Naive Bayes classifier (text features only with non-negative values)\n",
      "Features: 21047\n",
      "Testing accuracy score: 0.913\n",
      "\n",
      "Gaussian Naive Bayes classifier (text features and additional features which may include negative values)\n",
      "Features: 21048\n",
      "Testing accuracy score: 0.892\n",
      "\n",
      "Logistic Regression classifier (text features and additional features which may include negative values)\n",
      "Features: 21048\n",
      "Testing accuracy score: 0.903\n",
      "\u001b[4m\n",
      "1-grams and 2-grams, remove stop words:\u001b[0m\n",
      "\n",
      "Multinomial Naive Bayes classifier (text features only with non-negative values)\n",
      "Features: 15755\n",
      "Testing accuracy score: 0.922\n",
      "\n",
      "Gaussian Naive Bayes classifier (text features and additional features which may include negative values)\n",
      "Features: 15756\n",
      "Testing accuracy score: 0.867\n",
      "\n",
      "Logistic Regression classifier (text features and additional features which may include negative values)\n",
      "Features: 15756\n",
      "Testing accuracy score: 0.907\n",
      "\u001b[4m\n",
      "1-grams and 2-grams, remove stop words, only include terms that appear at least two times:\u001b[0m\n",
      "\n",
      "Multinomial Naive Bayes classifier (text features only with non-negative values)\n",
      "Features: 2881\n",
      "Testing accuracy score: 0.903\n",
      "\n",
      "Gaussian Naive Bayes classifier (text features and additional features which may include negative values)\n",
      "Features: 2882\n",
      "Testing accuracy score: 0.848\n",
      "\n",
      "Logistic Regression classifier (text features and additional features which may include negative values)\n",
      "Features: 2882\n",
      "Testing accuracy score: 0.905\n",
      "\u001b[4m\n",
      "1-grams and 2-grams, remove stop words, up to 9000 features:\u001b[0m\n",
      "\n",
      "Multinomial Naive Bayes classifier (text features only with non-negative values)\n",
      "Features: 9000\n",
      "Testing accuracy score: 0.915\n",
      "\n",
      "Gaussian Naive Bayes classifier (text features and additional features which may include negative values)\n",
      "Features: 9001\n",
      "Testing accuracy score: 0.867\n",
      "\n",
      "Logistic Regression classifier (text features and additional features which may include negative values)\n",
      "Features: 9001\n",
      "Testing accuracy score: 0.905\n"
     ]
    }
   ],
   "source": [
    "# Instantiate TfidfVectorizer to convert a collection of raw documents to a matrix of TF-IDF features\n",
    "# -> Equivalent to CountVectorizer followed by TfidfTransformer\n",
    "# Note: lowercase: convert all characters to lowercase before tokenizing; default is True\n",
    "#       stop_words: if 'english', a built-in stop word list for English is used; default is None\n",
    "#       ngram_range: tuple (min_n, max_n); the lower and upper boundary of the range of n-values for \n",
    "#                    different n-grams to be extracted; all values of n such that min_n <= n <= max_n will be used\n",
    "#       min_df: when building the vocabulary ignore terms that have a 'document frequency' strictly lower than the \n",
    "#               given threshold; this value is also called cut-off in the literature\n",
    "#       max_features: build a vocabulary that only considers the top max_features ordered by term frequency across the corpus\n",
    "print('\\033[4m' + '1-grams and 2-grams:' +  '\\033[0m')\n",
    "vect = TfidfVectorizer(lowercase=True, ngram_range=(1, 2))\n",
    "tokenize_test_mnb(vect)\n",
    "tokenize_test_gnb(vect)\n",
    "tokenize_test_logreg(vect)\n",
    "\n",
    "print('\\033[4m' + '\\n1-grams and 2-grams, remove stop words:' +  '\\033[0m')\n",
    "vect = TfidfVectorizer(lowercase=True, stop_words='english', ngram_range=(1, 2))\n",
    "tokenize_test_mnb(vect)\n",
    "tokenize_test_gnb(vect)\n",
    "tokenize_test_logreg(vect)\n",
    "\n",
    "print('\\033[4m' + '\\n1-grams and 2-grams, remove stop words, only include terms that appear at least two times:' +  '\\033[0m')\n",
    "vect = TfidfVectorizer(lowercase=True, stop_words='english', ngram_range=(1, 2), min_df=2)\n",
    "tokenize_test_mnb(vect)\n",
    "tokenize_test_gnb(vect)\n",
    "tokenize_test_logreg(vect)\n",
    "\n",
    "print('\\033[4m' + '\\n1-grams and 2-grams, remove stop words, up to 9000 features:' +  '\\033[0m')\n",
    "vect = TfidfVectorizer(lowercase=True, stop_words='english', ngram_range=(1, 2), max_features=9000)\n",
    "tokenize_test_mnb(vect)\n",
    "tokenize_test_gnb(vect)\n",
    "tokenize_test_logreg(vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chose final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate TfidfVectorizer to convert a collection of raw documents to a matrix of TF-IDF features\n",
    "# -> Equivalent to CountVectorizer followed by TfidfTransformer\n",
    "# Note: lowercase: convert all characters to lowercase before tokenizing; default is True\n",
    "#       stop_words: if 'english', a built-in stop word list for English is used; default is None\n",
    "#       ngram_range: tuple (min_n, max_n); the lower and upper boundary of the range of n-values for \n",
    "#                    different n-grams to be extracted; all values of n such that min_n <= n <= max_n will be used\n",
    "#       min_df: when building the vocabulary ignore terms that have a 'document frequency' strictly lower than the \n",
    "#               given threshold; this value is also called cut-off in the literature\n",
    "#       max_features: build a vocabulary that only considers the top max_features ordered by term frequency across the corpus\n",
    "vect = TfidfVectorizer(lowercase=True, stop_words='english', ngram_range=(1, 2), min_df=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 2881\n",
      "Testing accuracy score: 0.903\n"
     ]
    }
   ],
   "source": [
    "# Learn the vocabulary dictionary and return term-document matrix\n",
    "# -> This is equivalent to fit followed by transform, but more efficiently implemented\n",
    "X_train_dtm = vect.fit_transform(X_train.clean_text) \n",
    "    \n",
    "# Transform documents to document-term matrix\n",
    "# -> Extract token counts out of raw text documents using the vocabulary fitted with fit or the one provided to the constructor\n",
    "X_test_dtm = vect.transform(X_test.clean_text)\n",
    "    \n",
    "# Instantiate a Naive Bayes classifier for multinomial models and fit Naive Bayes classifier according to X, y\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_dtm, y_train)\n",
    "    \n",
    "# Return the number of columns (terms (aka \"tokens\" or \"features\"; individual words in this situation)) of the DataFrame\n",
    "print('Features: {}'.format(X_train_dtm.shape[1]))\n",
    "    \n",
    "# Predict the class using the Naive Bayes classifier\n",
    "y_pred_class = mnb.predict(X_test_dtm)\n",
    "    \n",
    "# Testing accuracy classification score\n",
    "print('Testing accuracy score:', round(metrics.accuracy_score(y_test, y_pred_class), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operational Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make predictions \n",
    "def prediction(X_test, classifier_object): \n",
    "  \n",
    "    # Predict the class labels\n",
    "    y_pred_class = classifier_object.predict(X_test)\n",
    "\n",
    "    print('Predicted values:')\n",
    "    print(y_pred_class)\n",
    "    print('')\n",
    "    return y_pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate accuracy\n",
    "def cal_accuracy(y_test, y_pred_class):\n",
    "      \n",
    "    # Testing accuracy classification score\n",
    "    print('Testing accuracy score:', round(metrics.accuracy_score(y_test, y_pred_class), 3))\n",
    "    print('')\n",
    "    \n",
    "    # Confusion matrix to evaluate the accuracy of a classification\n",
    "    print('Confusion Matrix:')\n",
    "    conmat = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "    print(pd.DataFrame(conmat,\n",
    "                       index=['True No Trump tweet', 'True Trump tweet'],\n",
    "                       columns=['Predicted No Trump tweet', 'Predicted Trump tweet']))\n",
    "    print('')\n",
    "    \n",
    "    # Build a text report showing the main classification metrics\n",
    "    print('Classification Report:')\n",
    "    print(metrics.classification_report(y_test, y_pred_class))\n",
    "    print('')\n",
    "    \n",
    "    # Area Under the Receiver Operating Characteristic Curve (ROC AUC)\n",
    "    print('ROC AUC:', round(metrics.roc_auc_score(y_test, y_pred_class), 3))\n",
    "    print('')\n",
    "    \n",
    "    # Log loss, aka logistic loss or cross-entropy loss\n",
    "    print('Log loss:', round(metrics.log_loss(y_test, y_pred_class), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Precision = Positive Predictive Value (PPV) = \\frac{True Positives}{True Positives + False Positives}--> completeness$$\n",
    "- \"How many of the items selected are relevant\"\n",
    "- Of the items placed into a class, how many of them are True Positives.\n",
    "- The ability of the classifier to not label a sample as positive if it is negative.\n",
    "<br>\n",
    "<br>\n",
    "$$Recall = True Positive Rate(Sensitivity) = \\frac{True Positives}{True Positives + False Negatives}-->exactness$$\n",
    "- \"How many of the relevant items are selected\"\n",
    "- Of the items that were suppose to be placed into a class, how many did we accurately place.\n",
    "- The ability of the classifier to find all the positive samples.\n",
    "<br>\n",
    "<br>\n",
    "$$F1Score = 2*\\frac{precision * recall}{precision + recall}$$\n",
    "- 0 <= F1 <= 1, where 0 is awful and 1 is perfection.\n",
    "- F1 is considered a harmonic mean as it averages Precision and Recall.\n",
    "- With classification models you often times have to choose what kind of error you are willing to increase in order to reduce the other and thus you may want to optimize Precision or Recall accordingly.\n",
    "- If you are uncertain which you should optimize, F1 score may be the metric of choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction using Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Using Naive Bayes Classifier:\n",
      "Predicted values:\n",
      "[1 1 0 1 1 1 1 0 1 0 0 0 1 1 1 1 1 0 0 1 1 1 0 0 0 0 1 1 1 0 1 0 0 1 1 0 0\n",
      " 1 1 0 1 0 1 0 0 1 1 1 0 1 0 1 1 0 0 1 0 1 0 1 1 0 0 1 1 1 0 1 1 1 0 1 1 1\n",
      " 0 1 1 1 1 1 0 0 1 0 0 1 0 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0\n",
      " 1 1 1 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1 1 1 1 0 0\n",
      " 0 1 1 1 0 0 1 0 1 1 0 1 1 1 1 0 0 0 1 0 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 0\n",
      " 1 1 0 1 0 0 1 0 1 1 1 0 0 0 1 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 0 1 0 0 1 1 1\n",
      " 0 1 1 0 0 1 1 0 1 0 1 1 0 1 0 1 1 1 0 1 0 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 0\n",
      " 1 0 1 0 0 1 0 0 1 0 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 1 1 0 1 1 0 1 0 0 0 1 0\n",
      " 0 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 1 0 1 0 1 0 1 1 0 1 1 0 0 0 1 0 0 1\n",
      " 1 0 0 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 0 0 1 0 0 1 0 0 1 0 0 0 1 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 1 1 0 0 0 1 0 1 1 1 0 0 1 0 1 0 0 0 1 1 1 0 1 1 1 1 0 0 0 1 0\n",
      " 0 1 1 0 0 1 0 0 1 0 1 0 0 0 1 0 0 1 1 0 1 0 0 1 0 0 1 0 0 0 1 1 1 1 0 1 0\n",
      " 0 1 1 1 0 1 1 0 1 1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1\n",
      " 1 0 1 0 1 0 1 0 1 0 0 0 1 0 1 1 0 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1\n",
      " 0 1 1 1 1 1 1 0 0 1 0 1 1 1 0 0 1 0 1 1 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 1\n",
      " 1 1 0 1 1 0 1 1 1 0 1 0 0 0 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1 0 0 0 1 0 0 1 0\n",
      " 0 0 0 1 0 1 1 1]\n",
      "\n",
      "Testing accuracy score: 0.903\n",
      "\n",
      "Confusion Matrix:\n",
      "                     Predicted No Trump tweet  Predicted Trump tweet\n",
      "True No Trump tweet                       258                     32\n",
      "True Trump tweet                           26                    284\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.89      0.90       290\n",
      "          1       0.90      0.92      0.91       310\n",
      "\n",
      "avg / total       0.90      0.90      0.90       600\n",
      "\n",
      "\n",
      "ROC AUC: 0.903\n",
      "\n",
      "Log loss: 3.339\n"
     ]
    }
   ],
   "source": [
    "print('Results Using Naive Bayes Classifier:') \n",
    "y_pred_class = prediction(X_test_dtm, mnb) \n",
    "cal_accuracy(y_test, y_pred_class) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Receiver Operating Characteristic (ROC) Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc_auc = metrics.roc_auc_score(y_test, mnb.predict(X_test_dtm))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, mnb.predict_proba(X_test_dtm)[:, 1])\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, label='AUC = %0.3f' % roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the Predicted Probability for a Random Pelosi and Trump tweet\n",
    "\n",
    "Below are provided a couple of tweets from both Pelosi and Trump.\n",
    "\n",
    "Estimate the predicted probability of being Trump for the two tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep our source as Tfidf vectors\n",
    "source_test = [\"Welcome to the Capitol, @EP_President Antonio Tajani! https://t.co/YEEb7kFmXF\",\n",
    "               \"It was not a campaign contribution, and there were no violations of the campaign finance laws by me. Fake News!\"]\n",
    "\n",
    "# NOTE:  Do not re-initialize the Tfidf vectorizor or the feature space will be overwritten and hence your transform \n",
    "#        will not match the number of features you trained your model on.\n",
    "#\n",
    "# This is why you only need to \"transform\" since you already \"fit\" previously.\n",
    "\n",
    "# Transform documents to document-term matrix\n",
    "X_test_dtm = vect.transform(source_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.76876224, 0.23123776],\n",
       "       [0.05627088, 0.94372912]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate predicted probability estimates of class membership\n",
    "# Each row sums to one and contains the probabilities of the point being a 0-Pelosi, 1-Trump\n",
    "mnb.predict_proba(X_test_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 1st column is probability of being Pelosi, and the 2nd column of being Trump. The classifier is getting it right."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
